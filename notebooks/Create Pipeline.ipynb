{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc5ef11-45f6-4ecf-a184-7b438e336154",
   "metadata": {},
   "source": [
    "# Image Modelling - Pipeline Creation (Python file)\n",
    "In this notebook we will cover: \n",
    "- how to prepare images for training a neural network and using shell commands instead of pandas to do so\n",
    "- Weâ€™ll start by preparing the data in a way that it can be loaded into tensorflow, followed by the loading itself and checking if everything went fine. \n",
    "- Each step will be defined as a function, which we will directly write into a python file. \n",
    "\n",
    "In the second notebook we will import and use those functions in order to train a neural network that classifies our pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47483726-487f-4192-9619-19393cf4344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any file that gets constructed by the notebook.\n",
    "## noch anpassen \n",
    "!rm -f image_modeling.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa45e36-1be0-443b-a8d8-63badf3ce8a7",
   "metadata": {},
   "source": [
    "The following cell defines a register cell magic which lets you write the content of a cell into a python script automatically, while still executing the cell. Mode 'a' (can be set with the -a flag) appends to the file while mode 'w' overwrites all existing lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c688f-64f6-4cfe-a750-a080f3f10a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some dark cell magic. Why not!\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def write_and_run(line, cell):\n",
    "    argz = line.split()\n",
    "    file = argz[-1]\n",
    "    mode = 'w'\n",
    "    if len(argz) == 2 and argz[0] == '-a':\n",
    "        mode = 'a'\n",
    "        print(\"Appended to file \", file)\n",
    "    else:\n",
    "        print('Written to file:', file)\n",
    "    with open(file, mode) as f:\n",
    "        f.write(cell.format(**globals()))        \n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6104569-ca79-4fd5-a5f9-ad2df66c84b8",
   "metadata": {},
   "source": [
    "Import needed libraries. `%%write_and_run image_modeling.py` is the call of the register cell magic from above in 'w' mode (default). It writes the imports at the beginning of the `image_modeling.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5228ad7-33bd-4840-8a7a-557150bb82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run image_modeling.py\n",
    "import pathlib\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62518635-52d3-4e86-8e80-979c756b1c72",
   "metadata": {},
   "source": [
    "Get the absolute path to the data folder, count all images and get the class names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321ec69-7efd-4193-b5ea-f3e595b75309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths as POSIX paths\n",
    "#home_path = str(pathlib.Path.home())\n",
    "data_dir = '../images'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "print(f'The total number of images is: {len(os.listdir(data_dir))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403717f-cda3-42c1-8ec1-934c6efa9b2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define functions to process the data\n",
    "\n",
    "From now on we will use python and Tensorflow to define some variables and functions to be used in the second notebook when we train our CNN to classify images of turtles.\n",
    "\n",
    "We set some parameters for the model and call the register cell magic `write_and_run` again this time with the `-a` flag. This makes sure that the content of the cell is appended to `image_modeling.py` and existing lines are not overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ad3ab-0874-4919-b8bd-369b6b897c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "#Get unique_turtle_ids from test.csv\n",
    "file = open(\"../data/train.csv\")\n",
    "reader = csv.reader(file)\n",
    "turtle_ids = []\n",
    "for i in list(reader):\n",
    "    turtle_ids.append(i[2])\n",
    "unique_turtle_ids = list(dict.fromkeys(turtle_ids))\n",
    "unique_turtle_ids = unique_turtle_ids[1:]\n",
    "\n",
    "file = open(\"../data/train.csv\")\n",
    "reader = csv.reader(file)\n",
    "lines = round(len(list(reader))*0.7)\n",
    "\n",
    "file = open(\"../data/train.csv\")\n",
    "reader = csv.reader(file)\n",
    "length_data = len(list(reader))\n",
    "\n",
    "# We set some parameters for the model\n",
    "HEIGHT = 224 #image height\n",
    "WIDTH = 224 #image width\n",
    "CHANNELS = 3 #image RGB channels\n",
    "CLASS_NAMES = unique_turtle_ids\n",
    "NCLASSES = len(CLASS_NAMES)\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "TRAINING_SIZE = lines\n",
    "VALIDATION_SIZE = length_data - lines                    \n",
    "VALIDATION_STEPS = VALIDATION_SIZE // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62fad04-0eb6-42c8-b165-9eddb24fe3ba",
   "metadata": {},
   "source": [
    "### Augmentation (to improve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0c52c-d10d-4d01-9abf-46cd5a41c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# flow_from_directory : Takes the path to a directory & generates batches of augmented data.\n",
    "# use \"rescale\" to scale array of original image pixel values to be between [0,1] and specify the parameter rescale=1./255.\n",
    "\n",
    "def preprocess(augment_randomly=False):\n",
    "    if augment_randomly==False:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "    return train_datagen, test_datagen\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "#x_col value : which will be the name of column(in dataframe) having file names\n",
    "#y_col value : which will be the name of column(in dataframe) having class/label\n",
    "\n",
    "train_dir=\"../images/\"\n",
    "data=pd.read_csv('../data/train.csv')\n",
    "data.image_id= data.image_id.apply(lambda x: x.strip()+\".JPG\")\n",
    "\n",
    "\n",
    "def generate_augmented_image(train_datagen, test_datagen, augment_randomly=False): \n",
    "    \n",
    "    if augment_randomly == False:\n",
    "        train_generator = train_datagen.flow_from_dataframe(dataframe =data[0:lines], \n",
    "                directory = train_dir,\n",
    "                x_col=\"image_id\" ,\n",
    "                y_col=\"turtle_id\",\n",
    "                target_size=(224, 224),\n",
    "                batch_size=32,\n",
    "                class_mode='categorical')\n",
    "                #save_to_dir=\"output/\",  if you wanna save the cropped images\n",
    "                #save_prefix=\"\",\n",
    "                #save_format='png')\n",
    "\n",
    "        validation_generator = train_datagen.flow_from_dataframe(dataframe =data[lines+1:-1], \n",
    "                directory = train_dir,\n",
    "                x_col=\"image_id\",\n",
    "                y_col=\"turtle_id\",\n",
    "                target_size=(224, 224),\n",
    "                batch_size=32,\n",
    "                class_mode='categorical')\n",
    "            \n",
    "        return train_generator, validation_generator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
