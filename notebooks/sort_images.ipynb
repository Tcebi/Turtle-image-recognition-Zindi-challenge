{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32f1139-e183-475c-ae8d-61a2897e514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary modules\n",
    "import shutil\n",
    "from imutils import paths\n",
    "from random import shuffle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a6c72-215d-4438-b64c-ab227420b478",
   "metadata": {},
   "source": [
    "## Sort train images into train and validation folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48fd1b0f-676f-41ad-85d7-4d165fb5ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_corrected.csv')\n",
    "train_data.image_id = train_data.image_id.apply(lambda x: x.strip()+\".jpg\")\n",
    "train_data['turtle_id-image_id'] = train_data.turtle_id + \"-\" + train_data.image_id\n",
    "train_data['turtle_id-image_location'] = train_data.turtle_id + \"-\" + train_data.image_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835d1a2c-96a0-4419-a743-ae9848365bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_location</th>\n",
       "      <th>turtle_id</th>\n",
       "      <th>turtle_id-image_id</th>\n",
       "      <th>turtle_id-image_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_009TNNQ8.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_Kf73l69A</td>\n",
       "      <td>t_id_Kf73l69A-ID_009TNNQ8.jpg</td>\n",
       "      <td>t_id_Kf73l69A-left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_010JDNBL.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>t_id_GrxmyS59</td>\n",
       "      <td>t_id_GrxmyS59-ID_010JDNBL.jpg</td>\n",
       "      <td>t_id_GrxmyS59-right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_01L54J3D.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "      <td>t_id_d6aYXtor-ID_01L54J3D.jpg</td>\n",
       "      <td>t_id_d6aYXtor-left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_02445SY2.jpg</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_GrxmyS59</td>\n",
       "      <td>t_id_GrxmyS59-ID_02445SY2.jpg</td>\n",
       "      <td>t_id_GrxmyS59-top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_026RZIZ9.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>t_id_hRzOoJ2t</td>\n",
       "      <td>t_id_hRzOoJ2t-ID_026RZIZ9.jpg</td>\n",
       "      <td>t_id_hRzOoJ2t-right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>ID_ZWHZBX92.jpg</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_Kc1tXDbJ</td>\n",
       "      <td>t_id_Kc1tXDbJ-ID_ZWHZBX92.jpg</td>\n",
       "      <td>t_id_Kc1tXDbJ-top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>ID_ZXM8MLS2.jpg</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_2QmcRkNj</td>\n",
       "      <td>t_id_2QmcRkNj-ID_ZXM8MLS2.jpg</td>\n",
       "      <td>t_id_2QmcRkNj-top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>ID_ZY15TQYT.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_stWei2Uq</td>\n",
       "      <td>t_id_stWei2Uq-ID_ZY15TQYT.jpg</td>\n",
       "      <td>t_id_stWei2Uq-left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>ID_ZYTRP3VN.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_ip3jsrYo</td>\n",
       "      <td>t_id_ip3jsrYo-ID_ZYTRP3VN.jpg</td>\n",
       "      <td>t_id_ip3jsrYo-left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>ID_ZZEGHRM5.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_m2JvEcsg</td>\n",
       "      <td>t_id_m2JvEcsg-ID_ZZEGHRM5.jpg</td>\n",
       "      <td>t_id_m2JvEcsg-left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2122 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id image_location      turtle_id  \\\n",
       "0     ID_009TNNQ8.jpg           left  t_id_Kf73l69A   \n",
       "1     ID_010JDNBL.jpg          right  t_id_GrxmyS59   \n",
       "2     ID_01L54J3D.jpg           left  t_id_d6aYXtor   \n",
       "3     ID_02445SY2.jpg            top  t_id_GrxmyS59   \n",
       "4     ID_026RZIZ9.jpg          right  t_id_hRzOoJ2t   \n",
       "...               ...            ...            ...   \n",
       "2117  ID_ZWHZBX92.jpg            top  t_id_Kc1tXDbJ   \n",
       "2118  ID_ZXM8MLS2.jpg            top  t_id_2QmcRkNj   \n",
       "2119  ID_ZY15TQYT.jpg           left  t_id_stWei2Uq   \n",
       "2120  ID_ZYTRP3VN.jpg           left  t_id_ip3jsrYo   \n",
       "2121  ID_ZZEGHRM5.jpg           left  t_id_m2JvEcsg   \n",
       "\n",
       "                 turtle_id-image_id turtle_id-image_location  \n",
       "0     t_id_Kf73l69A-ID_009TNNQ8.jpg       t_id_Kf73l69A-left  \n",
       "1     t_id_GrxmyS59-ID_010JDNBL.jpg      t_id_GrxmyS59-right  \n",
       "2     t_id_d6aYXtor-ID_01L54J3D.jpg       t_id_d6aYXtor-left  \n",
       "3     t_id_GrxmyS59-ID_02445SY2.jpg        t_id_GrxmyS59-top  \n",
       "4     t_id_hRzOoJ2t-ID_026RZIZ9.jpg      t_id_hRzOoJ2t-right  \n",
       "...                             ...                      ...  \n",
       "2117  t_id_Kc1tXDbJ-ID_ZWHZBX92.jpg        t_id_Kc1tXDbJ-top  \n",
       "2118  t_id_2QmcRkNj-ID_ZXM8MLS2.jpg        t_id_2QmcRkNj-top  \n",
       "2119  t_id_stWei2Uq-ID_ZY15TQYT.jpg       t_id_stWei2Uq-left  \n",
       "2120  t_id_ip3jsrYo-ID_ZYTRP3VN.jpg       t_id_ip3jsrYo-left  \n",
       "2121  t_id_m2JvEcsg-ID_ZZEGHRM5.jpg       t_id_m2JvEcsg-left  \n",
       "\n",
       "[2122 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c2b574b-e894-433a-9860-a7551aa8d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all pictures in the image_dir\n",
    "image_dir = '../images/'\n",
    "imagePaths = sorted(list(paths.list_images(image_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e895be3-fd96-4662-aa80-6ec5695b793b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    t_id_Kf73l69A\n",
       "1    t_id_GrxmyS59\n",
       "2    t_id_d6aYXtor\n",
       "3    t_id_GrxmyS59\n",
       "4    t_id_hRzOoJ2t\n",
       "Name: turtle_id, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store all the turtle_ids in train_data\n",
    "turtle_ids = train_data['turtle_id']\n",
    "turtle_ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b70d75-e294-4ec2-a361-d280fca5da91",
   "metadata": {},
   "source": [
    "## Sort images\n",
    "To sort the images you need to create a subfolder \"sorted_images\" into the main folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f26a674-4bad-469d-aecc-938a6dfc0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after listing all individuals create two empty folders for each individual \n",
    "#one for the training and another for the validaiton dataset\n",
    "\n",
    "#define the folder were the training and validation datasets will be placed\n",
    "if not os.path.exists(\"../sorted_images\"):\n",
    "    os.makedirs(\"../sorted_images\")\n",
    "root_dir=\"../sorted_images\"\n",
    "\n",
    "#loop through all individuals and create a folder for the training dataset\n",
    "# and a folder for the validation dataset\n",
    "for i in range(0, len(turtle_ids)):\n",
    "    train_dir=root_dir+\"/train/\"+turtle_ids[i]#variable with the full path of the training folder\n",
    "    val_dir=root_dir+\"/val/\"+turtle_ids[i]#variable with the full path of the validation folder\n",
    "    if not os.path.exists(train_dir):#condition for if the folder already exists\n",
    "        os.makedirs(train_dir)#create the folder\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f0bc9e9-a3e5-449d-bf20-8ce312df8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines will create a folder called \"new_turtle\" into our train and validation sub-folders. \n",
    "#This is necessary for our specific task. (Reminder: if the image most likelx does not belong to any turtle_id, the models needs to output \"new_turtle\")\n",
    "#These folders will not contain any pictures\n",
    "#os.makedirs(\"../sorted_images/train/new_turtle\")\n",
    "#os.makedirs(\"../sorted_images/val/new_turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92a27e5-d06b-456b-a0a4-c2ee9da7af77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check length of train_data, i.e. number of relevant pictures\n",
    "round(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1fa194-42dc-4bd7-a454-dcf7b5fff1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this example we are going to select 1822 (approx 86%) pictures for training and 300 (approx 14%) pictures for validation.\n",
    "#We setup the condition that the validation pictures should contain at least one picture per turtle_id for each image_location\n",
    "#as per now we have nothing to avoid having pictures that are very similiar in both datasets, which could result in overfitting the CNN\n",
    "\n",
    "#define the number of validation pictures and the number of training pictures\n",
    "N_val_pics=300\n",
    "N_train_pics=1822\n",
    "\n",
    "#create two empty lists to store the pictures files that are going to be moved to the training \n",
    "#and validation fodlers\n",
    "training_pictures=[]\n",
    "validation_pictures=[]\n",
    "\n",
    "#list to check if combination is already used\n",
    "turtle_id_image_location=[]\n",
    "\n",
    "#loop through each individual turtle_id and secondary image_location\n",
    "for index in range(0, len(train_data)):\n",
    "    if train_data['turtle_id-image_location'][index] not in turtle_id_image_location:\n",
    "        validation_pictures.append(train_data['turtle_id-image_id'][index])\n",
    "        turtle_id_image_location.append(train_data['turtle_id-image_location'][index])\n",
    "    else:\n",
    "        training_pictures.append(train_data['turtle_id-image_id'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633cf98a-d8d6-41f0-9173-76548ee0aa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if number of validation pictures is indeed 300\n",
    "len(validation_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc75d9e1-a0fd-4721-83fc-ae3f4fac24fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1822"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92407290-a1af-43f1-ae76-402df33094f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = []\n",
    "train_images = []\n",
    "#loop through the list of pictures\n",
    "#move the pictures files to the validation folder\n",
    "for i in range(0, len(validation_pictures)):\n",
    "    #get the picture name\n",
    "    val_file_name = image_dir + validation_pictures[i].split('-')[-1]\n",
    "    image_name = validation_pictures[i].split('-')[-1]\n",
    "\n",
    "    #create a variable with the directory and the name of the pictures file\n",
    "    output_name_val=root_dir+\"/val/\"+validation_pictures[i].split('-')[-0]+\"/\"+image_name\n",
    "       \n",
    "    #move the file\n",
    "    shutil.copy(val_file_name, output_name_val)\n",
    "    \n",
    "    # put the information into a DataFrame\n",
    "    val_images.append(image_name)\n",
    "\n",
    "for i in range(0, len(training_pictures)):\n",
    "    #get the picture name (e.g. \"01103F7D5A_2018-11-26_07-56-03.jpg\")\n",
    "    train_file_name = image_dir + training_pictures[i].split('-')[-1]\n",
    "    image_name = training_pictures[i].split('-')[-1]\n",
    "\n",
    "    #create a variable with the directory and the name of the pictures file\n",
    "    output_name_train=root_dir+\"/train/\"+training_pictures[i].split('-')[-0]+\"/\"+image_name\n",
    "       \n",
    "    #move the file\n",
    "    shutil.copy(train_file_name, output_name_train)    \n",
    "    \n",
    "    train_images.append(image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b472e06-4099-44d5-8c53-56de0a599dd3",
   "metadata": {},
   "source": [
    "## Sort test images\n",
    "To appriately use our Train_CNN pipeline, we need to move our test pictures into a subfolder, as well.\n",
    "\n",
    "As we don't know the turtle_id for these pictures, we will save them into subfolders containing their image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f7b25d0-f941-4726-aa75-a202ce4c644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/test_corrected.csv')\n",
    "test_data_jpg = pd.read_csv('../data/test_corrected.csv')\n",
    "test_data_jpg.image_id = test_data_jpg.image_id.apply(lambda x: x.strip()+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72716717-17e0-4dd2-bf56-e2177761f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the folder were the training and validation datasets will be placed\n",
    "root_dir=\"../sorted_images/\"\n",
    "image_dir=\"../images\"\n",
    "#loop through all individuals and create a folder for the test dataset\n",
    "for i in range(0, len(test_data)):\n",
    "    test_dir_folder= root_dir + \"test/\" + test_data['image_id'][i]#variable with the full path of the training folder\n",
    "    if not os.path.exists(test_dir_folder):#condition for if the folder already exists\n",
    "        os.makedirs(test_dir_folder)#create the folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4951475d-a48a-4d67-9f84-661bd285a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put images into the folders\n",
    "\n",
    "root_dir=\"../sorted_images/\"\n",
    "image_dir=\"../images/\"\n",
    "\n",
    "for i in range(0, len(test_data)):    \n",
    "    image_name = test_data_jpg['image_id'][i]\n",
    "    test_file_name = image_dir + image_name\n",
    "    output_name = root_dir + \"test/\" + test_data['image_id'][i] + \"/\" + image_name\n",
    "    #move the file\n",
    "    shutil.copy(test_file_name, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ee541-0175-485f-8e2e-abe2555afdd9",
   "metadata": {},
   "source": [
    "### We are ready to use Blur_Noise transformation on the pictures in our training folder. If not necessary, jump directly into Train_CNN to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919454d5-e8cc-4f97-a8de-efb339033b90",
   "metadata": {},
   "source": [
    "## Create dataframes with new folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98430e82-c3d0-4cb8-a468-f2dcb9f48f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_work_subdirs(gl):\n",
    "    for root, dirs, files in os.walk(gl[train_dir]):\n",
    "        dirs.sort()\n",
    "        if root == gl['pwd']:\n",
    "            for d2i in dirs:\n",
    "                print(d2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4b0500a-7599-45a9-aa1e-6ef24c73737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "train = []\n",
    "train_dir=\"../sorted_images/train/\"\n",
    "\n",
    "for r, d, f in os.walk(train_dir):\n",
    "    d.sort()\n",
    "    for file in sorted(f):\n",
    "        if \".jpg\" in file:\n",
    "            train.append((d,os.path.join(r,file)))\n",
    "\n",
    "df_train = pd.DataFrame(train,columns=['folder','image_id'])\n",
    "\n",
    "\n",
    "val = []\n",
    "val_dir=\"../sorted_images/val/\"\n",
    "\n",
    "for r, d, f in os.walk(val_dir):\n",
    "    d.sort()\n",
    "    for file in sorted(f):\n",
    "        if \".jpg\" in file:\n",
    "            val.append((d,os.path.join(r,file)))\n",
    "\n",
    "df_val = pd.DataFrame(val,columns=['folder','image_id'])\n",
    "\n",
    "test = []\n",
    "val_dir=\"../sorted_images/test/\"\n",
    "\n",
    "for r, d, f in os.walk(val_dir):\n",
    "    d.sort()\n",
    "    for file in sorted(f):\n",
    "        if \".jpg\" in file:\n",
    "            test.append((d,os.path.join(r,file)))\n",
    "\n",
    "df_test = pd.DataFrame(test,columns=['folder','image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "936bb9a7-ae03-466f-a21d-aa2f8097ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train['image_id']\n",
    "df_val = df_val['image_id']\n",
    "df_test = df_test['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "868ddfc5-eeac-42ad-b7e2-dd1b38df0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for line in range(len(df_train)):\n",
    "    train.append(df_train[line][-15:])\n",
    "\n",
    "val = []\n",
    "for line in range(len(df_val)):\n",
    "    val.append(df_val[line][-15:])\n",
    "\n",
    "test = []\n",
    "for line in range(len(df_test)):\n",
    "    test.append(df_test[line][-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3872f90-4dcc-4fd6-a54a-256b1eb60336",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_location_train = []\n",
    "for i in range(len(train)):\n",
    "    for j in range(len(train_data)):\n",
    "        if train[i] in train_data['image_id'][j]: \n",
    "            image_location_train.append(train_data['image_location'][j])\n",
    "            \n",
    "d_train = {'image_id':train,'image_location':image_location_train}   \n",
    "df_train = pd.DataFrame(d_train)\n",
    "df_train.to_csv('../data/df_sorted_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bde54d88-e905-4336-9c4d-42c47e5bf23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_location_val = []\n",
    "for i in range(len(val)):\n",
    "    for j in range(len(train_data)):\n",
    "        if val[i] in train_data['image_id'][j]: \n",
    "            image_location_val.append(train_data['image_location'][j])\n",
    "            \n",
    "d_val = {'image_id':val,'image_location':image_location_val}   \n",
    "df_val = pd.DataFrame(d_val)\n",
    "df_val.to_csv('../data/df_sorted_val.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efe9a020-f4dc-40ac-b8f8-46f48e4aab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_location_test = []\n",
    "for i in range(len(test)):\n",
    "    for j in range(len(test_data_jpg)):\n",
    "        if test[i] in test_data_jpg['image_id'][j]: \n",
    "            image_location_test.append(test_data_jpg['image_location'][j])\n",
    "            \n",
    "d_test = {'image_id':test,'image_location':image_location_test}   \n",
    "df_test = pd.DataFrame(d_test)\n",
    "df_test.to_csv('../data/df_sorted_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3381d-995c-4402-a488-bcd6803692a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
