{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed52df3-21d0-45f1-bd56-f6e67402ce8f",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "* Read the picture files\n",
    "* Decode JPEG content to RGB pixels\n",
    "* Convert this into floating tensors\n",
    "* Rescale pixel values (between 0 to 255) to [0,1] interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d8b791-974f-4d0a-8caa-ede55a07a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard \n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec4043-f9c7-4c31-94fa-5712fcd3c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the images into Train, Test folders\n",
    "import shutil, os\n",
    "\n",
    "#read labels from the csv\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "#Extract the labels and store in a new data frame called labels\n",
    "labels = df.sort_values('image_id')\n",
    "labels = df.sort_values ('turtle_id')\n",
    "#Create a Python list of Unique labels in data frame labels\n",
    "image_names = list(labels.image_id.unique())\n",
    "label_names = list(labels.turtle_id.unique())\n",
    "\n",
    "NCLASSES = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9f175-e15a-47e5-8d1a-3f2606a256a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the directories\n",
    "train_dir=\"../images/\"\n",
    "\n",
    "train=pd.read_csv('train.csv')\n",
    "test =pd.read_csv('train.csv')\n",
    "train.image_id= train.image_id.apply(lambda x: x.strip()+\".JPG\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a471ad5-bb5b-4a22-b992-16f9b3d360e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f37e70-1d19-488a-b83a-765a69d78864",
   "metadata": {},
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31939f5-46bb-4817-a85d-670b26f17571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[150, 150, 3], name='image_id'))\n",
    "    model.add(tf.keras.layers.Flatten(data_format=\"channels_last\"))\n",
    "    # We want to have a simple linear model so we have \n",
    "    # no activation function. \n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d726f-0ab1-4c78-b9b4-101d505348bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6b7bf-3dac-424f-b21c-cd1ca7141b47",
   "metadata": {},
   "source": [
    "# Keras Preprocessing + Augmentation using ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "- Rescale is a value by which we will multiply the data before any other processing. Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our models to process (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f1fc5-2936-445f-a3a4-e1b56dd791dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we could maybe use this as follows: \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# flow_from_directory : Takes the path to a directory & generates batches of augmented data.\n",
    "# use \"rescale\" to scale array of original image pixel values to be between [0,1] and specify the parameter rescale=1./255.\n",
    "\n",
    "def preprocess(augment_randomly=False):\n",
    "    if augment_randomly==False:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "    return train_datagen, test_datagen\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "#x_col value : which will be the name of column(in dataframe) having file names\n",
    "#y_col value : which will be the name of column(in dataframe) having class/label\n",
    "\n",
    "def generate_augmented_image(train_datagen, test_datagen, augment_randomly=False): \n",
    "    \n",
    "    if augment_randomly == False:\n",
    "        train_generator = train_datagen.flow_from_dataframe(dataframe =train[0:1700], \n",
    "                directory = train_dir,\n",
    "                x_col=\"image_id\" ,\n",
    "                y_col=\"turtle_id\",\n",
    "                target_size=(150, 150),\n",
    "                batch_size=32,\n",
    "                class_mode='categorical')\n",
    "                #save_to_dir=\"output/\",  if you wanna save the cropped images\n",
    "                #save_prefix=\"\",\n",
    "                #save_format='png')\n",
    "                \n",
    "        for _ in range(5):\n",
    "            img, label = train_generator.next()\n",
    "            print(img.shape)   #  (1,256,256,3)\n",
    "            plt.imshow(img[0])\n",
    "            plt.show()\n",
    "\n",
    "        validation_generator = train_datagen.flow_from_dataframe(dataframe =train[1701:2145], \n",
    "                directory = train_dir,\n",
    "                x_col=\"image_id\",\n",
    "                y_col=\"turtle_id\",\n",
    "                target_size=(150, 150),\n",
    "                batch_size=32,\n",
    "                class_mode='categorical')\n",
    "    \n",
    "            \n",
    "\n",
    "        return train_generator, validation_generator\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96ef46-38ee-4d4f-b0c5-5b8876cfb193",
   "metadata": {},
   "source": [
    "# Simple Model (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4187f-2e33-4d6a-b7a5-357ae12caf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model,batch_size=32):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        # The model outputs one-hot-encoded logits, so we need\n",
    "        # use the sparse version of the crossentropy loss.\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    train_datagen, test_datagen = preprocess()\n",
    "    train_generator, validation_generator = generate_augmented_image(train_datagen, test_datagen, augment_randomly=False)\n",
    "    \n",
    "    model.fit(\n",
    "        train_generator, \n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=1000 // batch_size, \n",
    "        epochs=10,\n",
    "        callbacks=[tensorboard_callback])\n",
    "    \n",
    "    #model.save_weights('simple_model.h5')  # always save your weights after training or during training\n",
    "    \n",
    "     \n",
    "    \n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb989c-2c82-437a-bbc9-14eac07d9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train our model using the prior defined functions \n",
    "model = linear_model()\n",
    "\n",
    "trained_model = train_and_evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf85740-6b77-452f-84a0-94392be035ac",
   "metadata": {},
   "source": [
    "Let us use Tensorboard to monitor our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fb911-bd4b-4b81-963c-ea3fa1919e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb6993-e6c5-496e-8904-6d35faf6ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a testing function.\n",
    "def test(model):\n",
    "    \n",
    "    model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bd3df-f95f-4a99-a1c5-74d01644fd17",
   "metadata": {},
   "source": [
    "# Transfer Learning - not ready obviously- :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc16917-1bf2-4298-b0f7-5a063cc4871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39c2a2-43c9-492e-816e-c61512ef3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b61c9-8f61-43ab-979a-258806819377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_learning_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(feature_extractor_layer)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=300, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f10ad2-d766-40ca-9515-291c294f4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transfer_learning_model()\n",
    "trained_model = train_and_evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e2fb0-c2d0-4401-873e-8f9193935ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
