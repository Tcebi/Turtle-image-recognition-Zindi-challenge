{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6869ebaa-30cb-41be-8072-0eff10713ca2",
   "metadata": {},
   "source": [
    "# Model for Prediction of Image Location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338069c-cfd0-42ef-bfcd-fb74ddf9d893",
   "metadata": {},
   "source": [
    "The extra images have no labels for image location. To make them useable like the training images, these labels have to be created.\n",
    "\n",
    "The image locations of training and test images were manually checked and wrong labels were corrected. The corrected dataframes were stored as *\\*_corrected.csv*.\n",
    "\n",
    "A model is fit on these labels to automatically predict the image location of the extra images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428939dc-1c6b-4654-9aa9-d75e4cdb4624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ffabd-37f7-437a-beca-f6a1677807ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850de411-a1c5-41ee-b333-b3a9aada847b",
   "metadata": {},
   "source": [
    "# Load and look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66057416-bd8a-45aa-855a-08db908dece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load csv-data\n",
    "image_dir = \"../images/\"\n",
    "train_data = pd.read_csv('../data/train_corrected.csv')\n",
    "train_data.image_id = train_data.image_id.apply(lambda x: x.strip()+\".JPG\")\n",
    "test_data = pd.read_csv('../data/test_corrected.csv')\n",
    "test_data.image_id = test_data.image_id.apply(lambda x: x.strip()+\".JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6412e-f626-46c9-9fff-dd15c96c959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e48d1-f29f-40e4-9bb0-8c6acc29a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='image_location',data=train_data).set_title(\"Data Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21d7d7-cfa9-4fcf-88eb-5ceac143918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931a221-2bb9-4ba0-9e7b-4432bac8e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='image_location',data=test_data).set_title(\"Data Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919bf6d-ada1-41e8-98c0-cdedf90d650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['image_location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c4ae2-e304-4e5f-b9cc-2c51ca2f2a44",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9982939-eb85-4c8b-b61b-671e4f7433d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get unique_turtle_ids from train.csv\n",
    "unique_turtle_ids = list(train_data['turtle_id'].unique())\n",
    "#Add category for new turtle for test set\n",
    "unique_turtle_ids.append(\"new_turtle\")\n",
    "#Get number of images for train/test split\n",
    "split = 0.9\n",
    "lines = round(len(train_data)*split)\n",
    "length_data = len(train_data)\n",
    "\n",
    "#We set some parameters for the model\n",
    "HEIGHT = 224 #image height\n",
    "WIDTH = 224 #image width\n",
    "CHANNELS = 3 #image RGB channels\n",
    "CLASS_NAMES = list(train_data['image_location'].unique())\n",
    "NCLASSES = 3\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "TRAINING_SIZE = lines\n",
    "TRAINING_STEPS = TRAINING_SIZE // BATCH_SIZE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dab391-56a2-4240-b569-56c171106818",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9fc9db-2b44-4017-9276-4c99020387dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(augment = True):\n",
    "    '''\n",
    "    Function to create ImageDataGenerator-Object to augment and scale image\n",
    "    input: augment=True\n",
    "    output: train_datagen, test_datagen\n",
    "    If augment is true, augmentation is applied on train_datagen, scaling for test_datagen.\n",
    "    If augment is false, only scaling is applied for both generators.\n",
    "    '''\n",
    "    if augment == True:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                rotation_range     = 40,\n",
    "                width_shift_range  = 0.2,\n",
    "                height_shift_range = 0.2,\n",
    "                # use \"rescale\" to scale array of original image pixel values to be between [0,1] and specify the parameter rescale=1./255.\n",
    "                rescale            = 1./255, \n",
    "                shear_range        = 0.2,\n",
    "                zoom_range         = 0.2,\n",
    "                horizontal_flip    = False,\n",
    "                fill_mode          = 'nearest')\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "    return train_datagen, test_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1918f16e-4dd5-430d-b668-6134f2c322ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_image_generator(df, train_datagen, test_datagen, training=True): \n",
    "    '''\n",
    "    Function to apply ImageDataGenerator-Object to images for augmentation and scaling\n",
    "    input: \n",
    "        dataframe for which the function should be used\n",
    "        train_datagen as ImageDataGenerator-Object\n",
    "        test_datagen as ImageDataGenerator-Object\n",
    "        training=True\n",
    "    output: train_generator and validation_generator or test_generator\n",
    "    If training is true, train_generator (augmented image and label) and validation_generator (scaled image and label) are returned.\n",
    "    If training is false, test_generator is returned containing scaled image, no label is returned.\n",
    "    '''\n",
    "    if training == True:\n",
    "        # Augment and scale images for training\n",
    "        # This is a generator that will read pictures found in directory, \n",
    "        # and indefinitely generate batches of augmented image data\n",
    "        # flow_from_directory: Takes the path to a directory & generates batches of augmented data.\n",
    "        train_generator = train_datagen.flow_from_dataframe(dataframe = df[0:lines], \n",
    "                directory   = image_dir,\n",
    "                x_col       = \"image_id\", #name of column(in dataframe) having file names\n",
    "                y_col       = \"image_location\", #name of column(in dataframe) having class/label\n",
    "                target_size = (HEIGHT, WIDTH),\n",
    "                batch_size  = BATCH_SIZE,\n",
    "                classes     = CLASS_NAMES,\n",
    "                class_mode  = 'categorical',\n",
    "                shuffle     = False)\n",
    "\n",
    "        # Scale images for validation\n",
    "        validation_generator = test_datagen.flow_from_dataframe(dataframe = df[lines:], \n",
    "                directory    = image_dir,\n",
    "                x_col        = \"image_id\",\n",
    "                y_col        = \"image_location\",\n",
    "                target_size  = (HEIGHT, WIDTH),\n",
    "                batch_size   = BATCH_SIZE,\n",
    "                classes      = CLASS_NAMES,\n",
    "                class_mode   = 'categorical',\n",
    "                shuffle      = False)\n",
    "        \n",
    "        return train_generator, validation_generator\n",
    "    \n",
    "    else:\n",
    "        # Scale images for testing, no target provided and returned\n",
    "        test_generator = test_datagen.flow_from_dataframe(dataframe = df, \n",
    "                directory   = image_dir,\n",
    "                x_col       = \"image_id\",\n",
    "                target_size = (HEIGHT, WIDTH),\n",
    "                batch_size  = BATCH_SIZE,\n",
    "                class_mode  = None,\n",
    "                shuffle     = False)\n",
    "            \n",
    "        return test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9017d8e-ff28-4c79-a8aa-59acedd630a0",
   "metadata": {},
   "source": [
    "## Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae935c-1f7b-484e-92aa-ade64627b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "base_model = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05495a3-ed7e-46e4-8cf9-37e5a9b73de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the last layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Add a final softmax layer with 3 nodes for classification output\n",
    "x = layers.Dense(NCLASSES, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(1e-5), loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "train_datagen, test_datagen = preprocess()\n",
    "train_generator, validation_generator = use_image_generator(train_data, train_datagen, test_datagen, training=True)\n",
    "    \n",
    "inception =  model.fit(\n",
    "        train_generator, \n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=TRAINING_STEPS, \n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412481e-2400-4c48-a5b5-1f9f1d8c2962",
   "metadata": {},
   "source": [
    "## Check confusion matrix & auc_score on test data with corrected image location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282bc33-f7bd-4b3a-86b3-70dbc802c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen, test_datagen = preprocess(augment = False)\n",
    "test_generator = use_image_generator(test_data, train_datagen, test_datagen, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34345a-f9f2-4f0b-89cf-5c4928210abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get probabilities for all turtle id's\n",
    "y_preds = model.predict(test_generator)\n",
    "#Get index of highest prediction\n",
    "y_preds = np.argmax(y_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c33035-a1d2-4096-8aa9-1bdd17c974ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get locations for test_data in numerical form\n",
    "test_loc = pd.factorize(test_data['image_location'], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7855f-452d-4104-ba72-b840ee12c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(test_loc, y_preds))\n",
    "print(confusion_matrix(test_loc, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f3484-4700-4eed-8152-c208d135eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "\n",
    "    for (idx, c_label) in enumerate(['left', 'top', 'right']):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a951c833-cda6-461f-b2f1-4a02e695c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot figure size\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n",
    "multiclass_roc_auc_score(test_loc, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30216a0-e6e5-4983-8938-fe7bb045b6e4",
   "metadata": {},
   "source": [
    "## Create image location on extra images with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd3120-ba94-4853-8d3f-278f89857721",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = pd.read_csv('../data/extra_images.csv')\n",
    "extra.image_id = extra.image_id.apply(lambda x: x.strip()+\".JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04fece-f595-4269-8b12-c63d543addb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e353e-4d7d-4a41-b105-5859fed1524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen, test_datagen = preprocess(augment = False)\n",
    "test_generator_extra = use_image_generator(extra, train_datagen, test_datagen, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9bce0-c91b-454d-a454-f79d97d91b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get probabilities for all turtle id's\n",
    "y_preds = model.predict(test_generator_extra)\n",
    "#Get index of highest prediction\n",
    "y_preds = np.argmax(y_preds, axis=1)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3561bd-ce20-426f-83ba-67cedb660e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame with top prediction in extra form\n",
    "list = []\n",
    "for id in y_preds:\n",
    "    list.append(CLASS_NAMES[id])\n",
    "\n",
    "title = ['image_location']\n",
    "\n",
    "image_location = pd.DataFrame(list, columns= title)\n",
    "\n",
    "#Insert image_ids from extra_data\n",
    "extra = pd.read_csv('../data/extra_images.csv')\n",
    "extra.insert(loc=1, column='image_location', value=image_location['image_location'])\n",
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1687de1-4ea4-403a-a629-4daf94e3d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save submission data as CSV\n",
    "extra.to_csv('../data/extra_images_loc.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556374da-08f0-4981-88bf-a6860927feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
