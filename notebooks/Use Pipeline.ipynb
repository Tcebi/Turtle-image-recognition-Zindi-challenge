{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6e27b1-188a-4afb-98f9-38818e508f23",
   "metadata": {},
   "source": [
    "# Image Modelling Part 2 - Use Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159167b4-2c3d-4c4d-9f75-2cd5462277c6",
   "metadata": {},
   "source": [
    "In the first notebook we used shell commands to prepare and split our data into a train and evaluation set. \n",
    "Furthermore, we defined some functions that will allow us to directly import our pictures and the corresponding class labels and if we want to also augment our data. \n",
    "Now, we will import the functions from the `image_modelling.py` file and use them to facilitate the data preparation step in this notebook. \n",
    "Lastly, we will use Tensorflow and Keras to create and train our neuronal network to identify turtles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118d51-c16b-4c7f-a6bf-6276f7a7c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "import tensorflow as tf\n",
    "import image_modeling   # import image_modeling.py file\n",
    "import tensorflow_hub as hub\n",
    "import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387f387-ca7d-4679-a05e-f92de2e9177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559448f7-019f-4047-901c-b477cd27e1e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for Tensorflow version\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1bb25-2f7f-479e-9aeb-fd56f13b9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import variables from image_modelling.py file\n",
    "file = open(\"../data/train.csv\")\n",
    "reader = csv.reader(file)\n",
    "\n",
    "HEIGHT = image_modeling.HEIGHT\n",
    "WIDTH = image_modeling.WIDTH\n",
    "NCLASSES = image_modeling.NCLASSES\n",
    "CLASS_NAMES = image_modeling.CLASS_NAMES\n",
    "BATCH_SIZE = image_modeling.BATCH_SIZE\n",
    "TRAINING_SIZE = image_modeling.TRAINING_SIZE\n",
    "TRAINING_STEPS = (TRAINING_SIZE // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b00031-663c-4004-bf86-4b64e6cd6e5a",
   "metadata": {},
   "source": [
    "Double check if the variables now contain the correct values. ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07961c12-db7b-402e-adfa-5e55ae4cb061",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can compare this output with the variables in the image_modelling.py file...\n",
    "print(HEIGHT)\n",
    "print(CLASS_NAMES)\n",
    "print(NCLASSES)\n",
    "print(TRAINING_STEPS)\n",
    "print(TRAINING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bda7a2-6102-4eff-93b9-e9b74e6cd405",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Building our Model\n",
    "\n",
    "Building and training a neural network involves various steps: \n",
    "1. define the architecture of the model\n",
    "2. compile the model\n",
    "3. train the model\n",
    "4. evaluate the model\n",
    "\n",
    "We have to start with defining the architecture. Our neural network will consist of several layers that are chained together. The input layer of our model will take our input data and hand it over to the flatten layer, which is responsible for reformatting our data. It will transform the format of our images from a three-dimensional array (HEIGHT, WIDTH, 3) to a one-dimensional array of size HEIGHT * WIDTH * 3. \n",
    "After the pixels are flattened we use a dense layer that returns a logits array with length `NCLASSES`. Each node in this layer contains a score that indicates the current image belongs to one of the n classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf568e1-d651-47ba-a15f-a4fa901170bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c3f1e-f4cd-4f1e-9abb-4c49c2205ee9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Lets create a simple linear model.\n",
    "def linear_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[HEIGHT, WIDTH, 3], name='image'))\n",
    "    model.add(tf.keras.layers.Flatten(data_format=\"channels_last\"))\n",
    "    # We want to have a simple linear model so we have \n",
    "    # no activation function. \n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c74046-b4ed-42ec-9816-4ad3f68a74a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Before we can train our model we need to compile it and define more settings. We have to choose a loss function, an optimizer and metrics. \n",
    "* The **loss function** measures how accurate the model is during training by calculating the model error. Usually we want to minimize this function to improve our model. As you can see in the [TensorFlow documentation](https://www.tensorflow.org/api_docs/python/tf/keras/losses) there are lot's of different loss functions to choose from. Some, e.g. the mean squared errror, hopefully look familiar to you. ;) \n",
    "* The **[optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)** defines how the model is updated based on the data and the loss function. One optimizer we've already covered earlier and which is also used for neural networks is the stochastic gradient descent (SGD) algorithm.   \n",
    "* The **metric** is used to monitor the training process. Here we can choose one of the metrics we've already encountered or [many more](https://www.tensorflow.org/api_docs/python/tf/keras/metrics). \n",
    "\n",
    "The following function compiles our model, loads the data using the `load_dataset()` function from the image_modelling.py file and trains the model on the loaded data. In the end the function returns our fitted model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea0e7a-60e1-405f-9b16-1fd512965815",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def train_and_evaluate(model,batch_size=32):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        # The model outputs one-hot-encoded logits, so we need\n",
    "        # use the sparse version of the crossentropy loss.\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    train_datagen, test_datagen = image_modeling.preprocess()\n",
    "    train_generator, validation_generator = image_modeling.use_image_generator(train_datagen, test_datagen, training=True)\n",
    "    \n",
    "    model.fit(\n",
    "        train_generator, \n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=TRAINING_STEPS, \n",
    "        epochs=10,\n",
    "        callbacks=[tensorboard_callback])\n",
    "          \n",
    "    return model\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fdebe-9f42-4061-ac71-d5d4ad7f0d1d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' # Build and train our model using the prior defined functions \n",
    "model = linear_model()\n",
    "trained_model = train_and_evaluate(model, BATCH_SIZE)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56088167-b93d-4639-ac63-40255d0e6ca8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Let us use Tensorboard to monitor our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b04f0c-1e01-4539-8771-ecd56286261b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "%tensorboard --logdir logs/fit\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8a69c-781d-41fc-8a4b-6f2d1b2de1bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Deep Neural Network\n",
    "\n",
    "Our simple model is not performing well. Maybe we can boost its performance by adding more layers.\n",
    "\n",
    "In the following `dnn_model()` function we add three more hidden, dense layers after the flatten layer to increase our models complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98cfb8-748e-43d4-bace-3af0733d2abe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Lets compare a neural network with hidden layers to the linear model\n",
    "def dnn_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[HEIGHT, WIDTH, 3], name='image'))\n",
    "    model.add(tf.keras.layers.Flatten(data_format=\"channels_last\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 40, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 40, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 30, activation = \"relu\"))\n",
    "    # We want to have a simple linear model so we have \n",
    "    # no activation function. \n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97794117-9aee-4fda-a85c-4b513dd9575e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Let us fit the deep neural network\n",
    "model = dnn_model()\n",
    "trained_model = train_and_evaluate(model, BATCH_SIZE)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383dc998-8c17-4195-9ea2-016cd783ce14",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Adding more hidden layers to our model, did indeed increase the accuracy. But still, the model's performance leaves something to be desired. Since we are working with images, switching to a convolutional neural network might help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f44d66-bc7c-4ea5-9d40-0234126ba2f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "CNN's are widely used for image recognition. They are regularized versions of DNN's able to be deeper without generating as much parameters due to its [convolutional](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/) and pooling layers.\n",
    "\n",
    "The architecture of our CNN is even more complex. This time we combine dense layers with `Conv2D` and `MaxPooling2D` layers. The convolutional and max pooling layers are inserted between the input layer and the flatten layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4670c8-ad93-4533-a1da-0c158e9f32c5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Now let us move on to a CNN model. \n",
    "def cnn_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[HEIGHT, WIDTH, 3], name='image'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=10, kernel_size=[5, 5], padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=[5, 5], padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=300, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15784cd7-83e1-450d-a4c4-a1c2d8bfb64d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "We can have a look at the architecture of our model with the method `.summary`. As you can see in the summary below, the output of each `Conv2D` and `MaxPooling2D` layer is also a three dimensional tensor of shape (height, width, channels). As we go deeper into the network the dimensions shrink. One advantage of the shrinking dimensions is that we can computationally afford to add more output channels in each convolutional layer. We can control the number of the output channels of those layers with the `filters` argument. \n",
    "\n",
    "However, at the end of our model we still need the combination of the flatten and dense layers to perform classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231a24d-56dc-4019-aa5a-b0bde1e6f9f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "model = cnn_model()\n",
    "model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814fc79-a858-4c48-a582-0ea8996cb4a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Let us fit the convolutional neural network\n",
    "model = cnn_model()\n",
    "trained_model = train_and_evaluate(model, BATCH_SIZE)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783eea5c-83af-40f1-8410-aebdbdcaa013",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "We see the CNN give better results than the DNN. But we still have heavy overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc42e33-a846-43dc-92bb-8a4fd3a5f125",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Transfer learning is when a model is trained on one task and is then reused for another task. One approach to transfer learning is fine-tuning. Here you take a trained neural net, exchange the last layer (head) for another layer, that fits the new task and then train the weights of the last layer only. \n",
    "\n",
    "First we need to download the headless model (this can take a while) we use MobileNetV2 which is a CNN that was trained on the [ImageNet](https://en.wikipedia.org/wiki/ImageNet) dataset, consisting of over 14 million images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53795c-03bb-4aae-955c-2ecd4ce3ddd5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,input_shape=(HEIGHT,WIDTH,3))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d37d23-a8c8-481c-bc07-b24dec923217",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "We only want to train the last layer therefore we freeze the layers of our headless model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd5b0b4-53c8-4d0f-9ea0-a3b2fff80779",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "feature_extractor_layer.trainable = False\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098ce17-6fe8-4f30-a378-5961b7e714e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Now we define our model by simply adding the output layer to our pretrained net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93b6e1-e8ce-4202-8351-94be03fbda34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def transfer_learning_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(feature_extractor_layer)\n",
    "    # TODO: add the correct output layer here\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=300, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211eae9-746e-4f39-a10b-d4d802538955",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Let us fit our transfer learning model\n",
    "model = transfer_learning_model()\n",
    "trained_model = train_and_evaluate(model, BATCH_SIZE)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3232d-a28c-411b-bcb3-afe050c5a7f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "%tensorboard --logdir logs/fit\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde9b069-d2b8-4a31-bc4c-3b66550b9479",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "As we see the results of fine-tuning surpass the results of the linear model, DNN and CNN. Fine-tuning is a very powerful approach which can generalize well even with limited amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e71867-08a1-4e3c-bc39-601f6d8bbff1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Transfer Learning InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caebcfe-6dfa-4006-8ec0-18534b1f3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "base_model = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c337c-9153-4cfb-98ac-c27094d4ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f949222-5f28-4d0b-a151-72d4ba7882ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the last layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Add a final softmax layer with 101 nodes for classification output\n",
    "x = layers.Dense(NCLASSES, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "train_datagen, test_datagen = image_modeling.preprocess()\n",
    "train_generator, validation_generator = image_modeling.use_image_generator(train_datagen, test_datagen, training=True)\n",
    "    \n",
    "inception =  model.fit(\n",
    "        train_generator, \n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=TRAINING_SIZE // BATCH_SIZE, \n",
    "        epochs=10,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa7d27-ab89-405c-95f4-0cabe34ea0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42290d6e-33d5-4a59-8e2f-e6189368705e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Concatinated Model with location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275eb7be-77ac-40bf-93fc-967cd4e1780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_data_loc = image_modeling.location_encoding(image_modeling.train_data)\n",
    "train_loc = train_data_loc[0:image_modeling.lines][['image_location_left', 'image_location_right', 'image_location_top']]\n",
    "val_loc = train_data_loc[image_modeling.lines:][['image_location_left', 'image_location_right', 'image_location_top']]\n",
    "train_loc.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf29e0-9e16-486c-8fd1-31ddd5365631",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Image model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "base_model = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "#InceptionV3 layers\n",
    "\n",
    "#change the last layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "img_model = tf.keras.models.Model(base_model.input, outputs=x)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80802853-a1d6-4dcc-8b70-b33e50a1537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Location model\n",
    "loc_input = layers.Input(shape=(image_modeling.lines,))\n",
    "y = layers.Dense(1024, activation='relu')(loc_input)\n",
    "loc_model = tf.keras.models.Model(loc_input, outputs=y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478071a-3611-428c-8eee-3cadf6376afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Combined model\n",
    "# combine the output of the two branches\n",
    "combined = layers.concatenate([img_model.output, loc_model.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "# Add a final softmax layer with 101 nodes for classification output\n",
    "z = layers.Dense(NCLASSES, activation='softmax')(combined)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = tf.keras.models.Model(inputs=[img_model.input, loc_model.input], outputs=z)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb34c79-0eae-4ba9-baff-9b3aef454790",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# NOT WORKING!!!\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "train_datagen, test_datagen = image_modeling.preprocess()\n",
    "train_generator, validation_generator = image_modeling.use_image_generator(train_datagen, test_datagen, training=True)\n",
    "    \n",
    "inception =  model.fit(\n",
    "        x=[train_generator[0], train_loc], y=train_generator[1],\n",
    "        validation_data=([validation_generator[0], val_loc],validation_generator[1]),\n",
    "        steps_per_epoch=TRAINING_SIZE // BATCH_SIZE, \n",
    "        epochs=10,\n",
    "        callbacks=[tensorboard_callback])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c493d-9402-4066-93db-135a8a731baf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Concatenate Model with partial model for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea95237-ebf4-4026-b423-a8d4ee1a3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "'''\n",
    "#InceptionV3 layers\n",
    "base_model = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "#change the last layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb03f9-1a42-4a1b-9c44-eefede35b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InceptionV3 layers\n",
    "base_model_left = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "#change the last layer\n",
    "for layer in base_model_left.layers:\n",
    "    layer.trainable = False\n",
    "    layer._name = layer.name + str(\"_left\")\n",
    "    \n",
    "#new layers for left image location\n",
    "left = layers.Flatten()(base_model_left.output)\n",
    "left = layers.Dense(1024, activation='relu')(left)\n",
    "left = layers.Dropout(0.2)(left)\n",
    "\n",
    "left = tf.keras.models.Model(base_model_left.input, outputs=left, name='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55da2c-d6a4-4be2-83ef-10bc28130206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InceptionV3 layers\n",
    "base_model_right = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "#change the last layer\n",
    "for layer in base_model_right.layers:\n",
    "    layer.trainable = False\n",
    "    layer._name = layer.name + str(\"_right\")\n",
    "\n",
    "#new layers for right image location\n",
    "right = layers.Flatten()(base_model_right.output)\n",
    "right = layers.Dense(1024, activation='relu')(right)\n",
    "right = layers.Dropout(0.2)(right)\n",
    "\n",
    "right = tf.keras.models.Model(base_model_right.input, outputs=right, name='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d911b3-d3db-4674-8950-1083ce037cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InceptionV3 layers\n",
    "base_model_top = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "#change the last layer\n",
    "for layer in base_model_top.layers:\n",
    "    layer.trainable = False\n",
    "    layer._name = layer.name + str(\"_top\")\n",
    "\n",
    "#new layers for right image location\n",
    "top = layers.Flatten()(base_model_top.output)\n",
    "top = layers.Dense(1024, activation='relu')(top)\n",
    "top = layers.Dropout(0.2)(top)\n",
    "\n",
    "top = tf.keras.models.Model(base_model_top.input, outputs=top, name='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127f32a-ee15-4b2c-addb-eb39ed8bd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model\n",
    "# combine the output of the two branches\n",
    "combined = layers.concatenate([left.output, right.output, top.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "# Add a final softmax layer with 101 nodes for classification output\n",
    "z = layers.Dense(NCLASSES, activation='softmax')(combined)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "combined_model = tf.keras.models.Model(inputs=[left.input, right.input, top.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0142a07-a5a1-4d3c-9e1e-60a0fa24bfea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#ImageDataGenerator\n",
    "train_datagen, test_datagen = image_modeling.preprocess()\n",
    "train_generator_left, validation_generator_left = image_modeling.use_image_generator(image_modeling.train_data_left, train_datagen, test_datagen, training=True)\n",
    "train_generator_right, validation_generator_right = image_modeling.use_image_generator(image_modeling.train_data_right, train_datagen, test_datagen, training=True)\n",
    "train_generator_top, validation_generator_top = image_modeling.use_image_generator(image_modeling.train_data_top, train_datagen, test_datagen, training=True)\n",
    "    \n",
    "inception =  combined_model.fit(\n",
    "        x=[train_generator_left[0][0], train_generator_right[0][0], train_generator_top[0][0]],\n",
    "        y=[train_generator_left[0][1], train_generator_right[0][1], train_generator_top[0][1]],\n",
    "        validation_data=([validation_generator_left[0][0], validation_generator_right[0][0], validation_generator_top[0][0]],\n",
    "                         [validation_generator_left[0][1], validation_generator_right[0][1], validation_generator_top[0][1]]),\n",
    "        steps_per_epoch=TRAINING_SIZE // BATCH_SIZE, \n",
    "        epochs=10,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e2457-3568-4994-8a1b-e59a29c168f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_left[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4b9f4-5804-40d7-b5b8-001f3b07ac8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_prefix(model, prefix: str, custom_objects=None):\n",
    "    '''https://nrasadi.medium.com/change-model-layer-name-in-tensorflow-keras-58771dd6bf1b\n",
    "    Adds a prefix to layers and model name while keeping the pre-trained weights\n",
    "    Arguments:\n",
    "        model: a tf.keras model\n",
    "        prefix: a string that would be added to before each layer name\n",
    "        custom_objects: if your model consists of custom layers you shoud add them pass them as a dictionary. \n",
    "            For more information read the following:\n",
    "            https://keras.io/guides/serialization_and_saving/#custom-objects\n",
    "    Returns:\n",
    "        new_model: a tf.keras model having same weights as the input model.\n",
    "    '''\n",
    "    \n",
    "    config = model.get_config()\n",
    "    old_to_new = {}\n",
    "    new_to_old = {}\n",
    "    \n",
    "    for layer in config['layers']:\n",
    "        new_name = prefix + layer['name']\n",
    "        old_to_new[layer['name']], new_to_old[new_name] = new_name, layer['name']\n",
    "        layer['name'] = new_name\n",
    "        layer['config']['name'] = new_name\n",
    "\n",
    "        if len(layer['inbound_nodes']) > 0:\n",
    "            for in_node in layer['inbound_nodes'][0]:\n",
    "                in_node[0] = old_to_new[in_node[0]]\n",
    "    \n",
    "    for input_layer in config['input_layers']:\n",
    "        input_layer[0] = old_to_new[input_layer[0]]\n",
    "    \n",
    "    for output_layer in config['output_layers']:\n",
    "        output_layer[0] = old_to_new[output_layer[0]]\n",
    "    \n",
    "    config['name'] = prefix + config['name']\n",
    "    new_model = tf.keras.Model().from_config(config, custom_objects)\n",
    "    \n",
    "    for layer in new_model.layers:\n",
    "        layer.set_weights(model.get_layer(new_to_old[layer.name]).get_weights())\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c6793-87e9-4e2f-9d9d-f51fb83f394d",
   "metadata": {},
   "source": [
    "### 3 different models for location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49d3434-6154-4353-91b4-36eea172a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb99ae-b812-4f66-8c7e-cc015330e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InceptionV3 layers\n",
    "base_model = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "#change the last layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b423e9-16b8-4f54-b9d1-571f4b019b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new layers for left image location\n",
    "left = layers.Flatten()(base_model.output)\n",
    "left = layers.Dense(1024, activation='relu')(left)\n",
    "left = layers.Dropout(0.2)(left)\n",
    "\n",
    "# Add a final softmax layer with 101 nodes for classification output\n",
    "left = layers.Dense(NCLASSES, activation='softmax')(left)\n",
    "\n",
    "model_left = tf.keras.models.Model(base_model.input, left)\n",
    "\n",
    "model_left.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "train_datagen, test_datagen = image_modeling.preprocess()\n",
    "train_generator_left, validation_generator_left = image_modeling.use_image_generator(image_modeling.train_data_left, \n",
    "                                                                                     train_datagen, test_datagen, training=True)\n",
    "    \n",
    "inception_left =  model_left.fit(\n",
    "        train_generator_left, \n",
    "        validation_data=validation_generator_left,\n",
    "        steps_per_epoch=TRAINING_SIZE // BATCH_SIZE, \n",
    "        epochs=20,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f38c9-c297-426e-b1fb-a5b670771335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new layers for left image location\n",
    "right = layers.Flatten()(base_model.output)\n",
    "right = layers.Dense(1024, activation='relu')(right)\n",
    "right = layers.Dropout(0.2)(right)\n",
    "\n",
    "# Add a final softmax layer with 101 nodes for classification output\n",
    "right = layers.Dense(NCLASSES, activation='softmax')(right)\n",
    "\n",
    "model_right = tf.keras.models.Model(base_model.input, right)\n",
    "\n",
    "model_right.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "train_datagen, test_datagen = image_modeling.preprocess()\n",
    "train_generator_right, validation_generator_right = image_modeling.use_image_generator(image_modeling.train_data_right, \n",
    "                                                                                     train_datagen, test_datagen, training=True)\n",
    "    \n",
    "inception_right =  model_right.fit(\n",
    "        train_generator_right, \n",
    "        validation_data=validation_generator_right,\n",
    "        steps_per_epoch=TRAINING_SIZE // BATCH_SIZE, \n",
    "        epochs=20,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f91ea-3cd5-4768-b427-ca6a0c32234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new layers for left image location\n",
    "top = layers.Flatten()(base_model.output)\n",
    "top = layers.Dense(1024, activation='relu')(top)\n",
    "top = layers.Dropout(0.2)(top)\n",
    "\n",
    "# Add a final softmax layer with 101 nodes for classification output\n",
    "top = layers.Dense(NCLASSES, activation='softmax')(top)\n",
    "\n",
    "model_top = tf.keras.models.Model(base_model.input, top)\n",
    "\n",
    "model_top.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "train_datagen, test_datagen = image_modeling.preprocess()\n",
    "train_generator_top, validation_generator_top = image_modeling.use_image_generator(image_modeling.train_data_top, \n",
    "                                                                                     train_datagen, test_datagen, training=True)\n",
    "    \n",
    "inception_top =  model_top.fit(\n",
    "        train_generator_top, \n",
    "        validation_data=validation_generator_top,\n",
    "        steps_per_epoch=TRAINING_SIZE // BATCH_SIZE, \n",
    "        epochs=20,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e7bdf-bcb6-40d8-a5f6-3ff26a16447b",
   "metadata": {},
   "source": [
    "## Prepare data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbaaa0-ba92-4c7d-ab65-4330272f3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = image_modeling.test_data\n",
    "test_generator = image_modeling.use_image_generator(test_data, train_datagen, test_datagen, training=False)\n",
    "#test_generator[489].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e90fd-211f-437e-a83e-060d53cb9bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "for index in range(len(test_data)):\n",
    "    if test_data['image_location'][index] == 'left': \n",
    "        y_pred = model_left.predict(test_generator[index])\n",
    "        y_preds.append(y_pred.flatten())\n",
    "    elif test_data['image_location'][index] == 'right':\n",
    "        y_pred = model_right.predict(test_generator[index])\n",
    "        y_preds.append(y_pred.flatten())\n",
    "    else:\n",
    "        y_pred = model_top.predict(test_generator[index])\n",
    "        y_preds.append(y_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d4d3b-ca96-4479-bf18-6404d8daf8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get probabilities for all turtle id's\n",
    "#y_preds = model.predict(test_generator)\n",
    "print(y_preds[0])\n",
    "#Get indices from top 5 predictions\n",
    "# Corrected: [:,:-6:-1] instead of [:,-5:]\n",
    "y_preds = np.argsort(y_preds, axis=1)[:,:-6:-1]\n",
    "\n",
    "#Save indices of top 5 predictions as dataframe\n",
    "df = pd.DataFrame(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1734682-babc-46fd-876c-51a5628a77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b50197-f92b-4915-ac41-f3c549af0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame with top 5 predictions in submission form\n",
    "list = []\n",
    "array = []\n",
    "for line in y_preds:\n",
    "    for id in line:\n",
    "        list.append(CLASS_NAMES[id])\n",
    "    array.append(list)\n",
    "    list = []\n",
    "\n",
    "titles = ['prediction1', 'prediction2','prediction3','prediction4','prediction5']\n",
    "\n",
    "submission = pd.DataFrame(array, columns= titles)\n",
    "\n",
    "#Insert image_ids from test_data\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "submission.insert(loc=0, column='image_id', value=test_data['image_id'])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f378f-7f5d-4310-a54e-5b153374ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save submission data as CSV\n",
    "submission.to_csv('../data/submission_shuffleFalse.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c1d8bb-489b-4bf8-91d5-65da0ce4aeda",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84066b-91ba-48b9-af7e-511cd9c0e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "'''\n",
    "model.save('InceptionV3')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155bff5d-fe2c-4000-a1c0-394b45a5a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "'''\n",
    "loaded_model = tf.keras.models.load_model('InceptionV3)\n",
    "loaded_model.layers[0].input_shape #(None, 150, 150, 3)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
