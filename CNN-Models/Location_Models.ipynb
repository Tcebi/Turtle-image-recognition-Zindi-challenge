{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fa2f4c-3869-4410-ba14-c0f08b326afc",
   "metadata": {},
   "source": [
    "# Three Models for location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfcdf7f-ff9d-4f2c-b297-6c9a7f43c18d",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ed6aa-4db9-4d5d-8e07-428eae989afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for data preparation\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Import packages for modeling\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import datetime\n",
    "import csv\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b456e5-1629-465b-b11e-8ee5fd3afa09",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a52691-4cff-41b7-80b0-e3cb264dab21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Path to images\n",
    "image_dir = \"../images/\"\n",
    "\n",
    "#Load train-data\n",
    "train_data = pd.read_csv('../data/train_corrected.csv')\n",
    "train_data.image_id = train_data.image_id.apply(lambda x: x.strip()+\".JPG\")\n",
    "train_data.image_location = train_data.image_location.apply(lambda x: x.lower())\n",
    "\n",
    "#Load test data\n",
    "test_data = pd.read_csv('../data/test_corrected.csv')\n",
    "test_data.image_id = test_data.image_id.apply(lambda x: x.strip()+\".JPG\")\n",
    "test_data.image_location = test_data.image_location.apply(lambda x: x.lower())\n",
    "\n",
    "#Split train data using image location\n",
    "train_data_left = train_data.loc[train_data['image_location']=='left']\n",
    "train_data_right = train_data.loc[train_data['image_location']=='right']\n",
    "train_data_top = train_data.loc[train_data['image_location']=='top']\n",
    "\n",
    "#Get unique_turtle_ids from train.csv\n",
    "unique_turtle_ids = list(train_data['turtle_id'].unique())\n",
    "#Add category for new turtle for test set\n",
    "unique_turtle_ids.append(\"new_turtle\")\n",
    "\n",
    "#Get number of images for train/test split\n",
    "split = 0.9\n",
    "lines = round(min(len(train_data_left),len(train_data_right),len(train_data_top))*split)\n",
    "\n",
    "#We set some parameters for the model\n",
    "HEIGHT = 224 #image height\n",
    "WIDTH = 224 #image width\n",
    "CHANNELS = 3 #image RGB channels\n",
    "CLASS_NAMES = unique_turtle_ids\n",
    "NCLASSES = len(CLASS_NAMES)\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "TRAINING_SIZE = lines\n",
    "TRAINING_STEPS = (TRAINING_SIZE // BATCH_SIZE)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3c8c5-09ea-415c-a26c-edcebd09baa1",
   "metadata": {},
   "source": [
    "## Preparing data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4b7e7-7d3d-4cf2-970d-87ae3e551314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(augment = True):\n",
    "    '''\n",
    "    Function to create ImageDataGenerator-Object to augment and scale image\n",
    "    input: augment=True\n",
    "    output: train_datagen, test_datagen\n",
    "    If augment is true, augmentation is applied on train_datagen, scaling for test_datagen.\n",
    "    If augment is false, only scaling is applied for both generators.\n",
    "    '''\n",
    "    if augment == True:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                rotation_range     = 40,\n",
    "                width_shift_range  = 0.2,\n",
    "                height_shift_range = 0.2,\n",
    "                # use \"rescale\" to scale array of original image pixel values to be between [0,1] and specify the parameter rescale=1./255.\n",
    "                rescale            = 1./255, \n",
    "                shear_range        = 0.2,\n",
    "                zoom_range         = 0.2,\n",
    "                horizontal_flip    = False,\n",
    "                fill_mode          = 'nearest')\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "    return train_datagen, test_datagen\n",
    "\n",
    "\n",
    "def use_image_generator(df, train_datagen, test_datagen, training=True): \n",
    "    '''\n",
    "    Function to apply ImageDataGenerator-Object to images for augmentation and scaling\n",
    "    input: \n",
    "        dataframe for which the function should be used\n",
    "        train_datagen as ImageDataGenerator-object\n",
    "        test_datagen as ImageDataGenerator-object\n",
    "        training=True\n",
    "    output: train_generator and validation_generator or test_generator\n",
    "    If training is true, train_generator (augmented image and label) and validation_generator (scaled image and label) are returned.\n",
    "    If training is false, test_generator is returned containing scaled image, no label is returned.\n",
    "    '''\n",
    "    if training == True:\n",
    "        # Augment and scale images for training\n",
    "        # This is a generator that will read pictures found in directory, \n",
    "        # and indefinitely generate batches of augmented image data\n",
    "        # flow_from_directory: Takes the path to a directory & generates batches of augmented data.\n",
    "        train_generator = train_datagen.flow_from_dataframe(dataframe = df[0:lines], \n",
    "                directory   = image_dir,\n",
    "                x_col       = \"image_id\", #name of column(in dataframe) having file names\n",
    "                y_col       = \"turtle_id\", #name of column(in dataframe) having class/label\n",
    "                target_size = (HEIGHT, WIDTH),\n",
    "                batch_size  = BATCH_SIZE,\n",
    "                classes     = CLASS_NAMES,\n",
    "                class_mode  = 'categorical',\n",
    "                shuffle     = True)\n",
    "\n",
    "        # Scale images for validation\n",
    "        validation_generator = test_datagen.flow_from_dataframe(dataframe = df[lines:], \n",
    "                directory    = image_dir,\n",
    "                x_col        = \"image_id\",\n",
    "                y_col        = \"turtle_id\",\n",
    "                target_size  = (HEIGHT, WIDTH),\n",
    "                batch_size   = BATCH_SIZE,\n",
    "                classes      = CLASS_NAMES,\n",
    "                class_mode   = 'categorical',\n",
    "                shuffle      = True)\n",
    "        \n",
    "        return train_generator, validation_generator\n",
    "    \n",
    "    else:\n",
    "        # Scale images for testing, no target provided and returned\n",
    "        test_generator = test_datagen.flow_from_dataframe(dataframe = df, \n",
    "                directory   = image_dir,\n",
    "                x_col       = \"image_id\",\n",
    "                target_size = (HEIGHT, WIDTH),\n",
    "                batch_size  = 1,\n",
    "                class_mode  = None,\n",
    "                shuffle     = False)\n",
    "            \n",
    "        return test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ff5f6-a30f-4950-b05d-bfdb3aca6c96",
   "metadata": {},
   "source": [
    "## One model per image location (Transfer Learning using InceptionV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc862b7f-aa0a-495f-8956-d849c83cd836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92fb3d-07cd-4e43-bf54-3d20f32c1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InceptionV3 layers\n",
    "base_model = InceptionV3(input_shape = (HEIGHT, WIDTH, CHANNELS), include_top = False, weights = 'imagenet')\n",
    "\n",
    "#Freeze layers for training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Set Epochs for training\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db445ec0-ba47-42e2-9b6d-5b795eeb9d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model for images taken from LEFT side\n",
    "\n",
    "#new layers for left image location\n",
    "left = layers.Flatten()(base_model.output)\n",
    "left = layers.Dense(1024, activation='relu')(left)\n",
    "left = layers.Dropout(0.2)(left)\n",
    "\n",
    "# Add a final softmax layer with 101 nodes for classification output\n",
    "left = layers.Dense(NCLASSES, activation='softmax')(left)\n",
    "\n",
    "model_left = tf.keras.models.Model(base_model.input, left)\n",
    "\n",
    "#Compile model and set log and callbacks\n",
    "model_left.compile(optimizer = tf.keras.optimizers.Adam(1e-5), loss = 'binary_crossentropy', \n",
    "                   metrics = tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#Load and preprocess data\n",
    "train_datagen, test_datagen = preprocess()\n",
    "train_generator_left, validation_generator_left = use_image_generator(train_data_left, \n",
    "                                                  train_datagen, test_datagen, training=True)\n",
    "\n",
    "#Fit model\n",
    "inception_left =  model_left.fit(\n",
    "        train_generator_left, \n",
    "        validation_data=validation_generator_left,\n",
    "        steps_per_epoch=TRAINING_SIZE // BATCH_SIZE, \n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d169782-38ae-4a4f-b2f4-7d1fbdf8b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model for images taken from RIGHT side\n",
    "\n",
    "#new layers for right image location\n",
    "right = layers.Flatten()(base_model.output)\n",
    "right = layers.Dense(1024, activation='relu')(right)\n",
    "right = layers.Dropout(0.2)(right)\n",
    "\n",
    "# Add a final softmax layer with 101 nodes for classification output\n",
    "right = layers.Dense(NCLASSES, activation='softmax')(right)\n",
    "\n",
    "model_right = tf.keras.models.Model(base_model.input, right)\n",
    "\n",
    "#Compile model and set log and callbacks\n",
    "model_right.compile(optimizer = tf.keras.optimizers.Adam(1e-5), loss = 'binary_crossentropy', metrics = tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#Load and preprocess data\n",
    "train_datagen, test_datagen = preprocess()\n",
    "train_generator_right, validation_generator_right = use_image_generator(train_data_right, \n",
    "                                                    train_datagen, test_datagen, training=True)\n",
    "    \n",
    "#Fit model\n",
    "inception_right =  model_right.fit(\n",
    "        train_generator_right, \n",
    "        validation_data=validation_generator_right,\n",
    "        steps_per_epoch=TRAINING_SIZE // BATCH_SIZE, \n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd4ed9-08de-4fc8-9018-4bab96fdddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model for images taken from TOP side\n",
    "\n",
    "#new layers for top image location\n",
    "top = layers.Flatten()(base_model.output)\n",
    "top = layers.Dense(1024, activation='relu')(top)\n",
    "top = layers.Dropout(0.2)(top)\n",
    "\n",
    "# Add a final softmax layer with 101 nodes for classification output\n",
    "top = layers.Dense(NCLASSES, activation='softmax')(top)\n",
    "\n",
    "model_top = tf.keras.models.Model(base_model.input, top)\n",
    "\n",
    "#Compile model and set log and callbacks\n",
    "model_top.compile(optimizer = tf.keras.optimizers.Adam(1e-5), loss = 'binary_crossentropy', metrics = tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#Load and preprocess data\n",
    "train_datagen, test_datagen = preprocess()\n",
    "train_generator_top, validation_generator_top = use_image_generator(train_data_top, \n",
    "                                                train_datagen, test_datagen, training=True)\n",
    "\n",
    "#Fit model\n",
    "inception_top =  model_top.fit(\n",
    "        train_generator_top, \n",
    "        validation_data=validation_generator_top,\n",
    "        steps_per_epoch=TRAINING_SIZE // BATCH_SIZE, \n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ccf3a-6d3f-41e4-81ba-e837d5a97149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save models\n",
    "#model_left.save('model_left')\n",
    "#model_right.save('model_right')\n",
    "#model_top.save('model_top')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad1807-65e8-4cee-a1c7-a9837e5829d3",
   "metadata": {},
   "source": [
    "## Prepare data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8e4dd-a5da-4cb6-8bdb-4266beaba673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare prediction for test data\n",
    "test_generator = use_image_generator(test_data, train_datagen, test_datagen, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ff837-37a2-469b-8a2a-79c19f1fc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict using three models for each location\n",
    "y_preds = []\n",
    "for index in range(len(test_data)):\n",
    "    if test_data['image_location'][index] == 'left': \n",
    "        y_pred = model_left.predict(test_generator[index])\n",
    "        y_preds.append(y_pred.flatten())\n",
    "    elif test_data['image_location'][index] == 'right':\n",
    "        y_pred = model_right.predict(test_generator[index])\n",
    "        y_preds.append(y_pred.flatten())\n",
    "    else:\n",
    "        y_pred = model_top.predict(test_generator[index])\n",
    "        y_preds.append(y_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d8e86-e8cc-407a-be25-6085c77d379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get indices from top 5 predictions\n",
    "# Corrected: [:,:-6:-1] instead of [:,-5:] so that best prediction comes first\n",
    "y_preds = np.argsort(y_preds, axis=1)[:,:-6:-1]\n",
    "\n",
    "#Save indices of top 5 predictions as dataframe\n",
    "df = pd.DataFrame(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88666f18-cbcd-46bc-834f-77ffe1806b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame with top 5 predictions in submission form\n",
    "list = []\n",
    "array = []\n",
    "for line in y_preds:\n",
    "    for id in line:\n",
    "        list.append(CLASS_NAMES[id])\n",
    "    array.append(list)\n",
    "    list = []\n",
    "\n",
    "titles = ['prediction1', 'prediction2','prediction3','prediction4','prediction5']\n",
    "\n",
    "submission = pd.DataFrame(array, columns= titles)\n",
    "\n",
    "#Insert image_ids from test_data\n",
    "test_data = pd.read_csv('../data/test.csv') #image_id without appended .JPG\n",
    "submission.insert(loc=0, column='image_id', value=test_data['image_id']) #Insert image_id in first column\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ded01-6350-4d01-882e-684c23761d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save submission data as CSV\n",
    "submission.to_csv('../data/submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
