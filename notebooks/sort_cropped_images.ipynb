{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119608a-1c14-4c94-a9c5-6d8851884c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary modules\n",
    "import shutil\n",
    "from imutils import paths\n",
    "from random import shuffle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a477baa-c4c3-4a82-b886-b1758c42968d",
   "metadata": {},
   "source": [
    "## Sort train images into train and validation folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbcf2f-c4ea-4e11-9d1e-61bdbdeb6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_corrected.csv')\n",
    "train_data.image_id = train_data.image_id.apply(lambda x: x.strip()+\".JPG\")\n",
    "train_data['turtle_id-image_id'] = train_data.turtle_id + \"-\" + train_data.image_id\n",
    "train_data['turtle_id-image_location'] = train_data.turtle_id + \"-\" + train_data.image_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e775a-f643-49c5-bb05-963cd9bcd79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea79691-897c-469e-9d04-a9aa633aaaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all pictures in the image_dir\n",
    "image_dir = '../cropped_unsorted/'\n",
    "imagePaths = sorted(list(paths.list_images(image_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e4e09-f3c2-4e31-889f-c43f9c4b0260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all the turtle_ids in train_data\n",
    "turtle_ids = train_data['turtle_id']\n",
    "turtle_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df3b01-f993-44e4-9bb9-7390401827d6",
   "metadata": {},
   "source": [
    "## Sort images\n",
    "To sort the images you need to create a subfolder \"sorted_images\" into the main folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84d25e-0c87-4007-b580-882c6a00644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after listing all individuals create two empty folders for each individual \n",
    "#one for the training and another for the validaiton dataset\n",
    "\n",
    "#define the folder were the training and validation datasets will be placed\n",
    "if not os.path.exists(\"../cropped_sorted\"):\n",
    "    os.makedirs(\"../cropped_sorted\")\n",
    "root_dir=\"../cropped_sorted\"\n",
    "\n",
    "#loop through all individuals and create a folder for the training dataset\n",
    "# and a folder for the validation dataset\n",
    "for i in range(0, len(turtle_ids)):\n",
    "    train_dir=root_dir+\"/train/\"+turtle_ids[i]#variable with the full path of the training folder\n",
    "    val_dir=root_dir+\"/val/\"+turtle_ids[i]#variable with the full path of the validation folder\n",
    "    if not os.path.exists(train_dir):#condition for if the folder already exists\n",
    "        os.makedirs(train_dir)#create the folder\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e50376-fcde-49e7-8e6b-317679b0da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines will create a folder called \"new_turtle\" into our train and validation sub-folders. \n",
    "#This is necessary for our specific task. (Reminder: if the image most likelx does not belong to any turtle_id, the models needs to output \"new_turtle\")\n",
    "#These folders will not contain any pictures\n",
    "#os.makedirs(\"../sorted_images/train/new_turtle\")\n",
    "#os.makedirs(\"../sorted_images/val/new_turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa4b39-31f3-4670-a169-135e926e821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check length of train_data, i.e. number of relevant pictures\n",
    "round(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053cd488-da5c-40ff-b90b-f82995998ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this example we are going to select 1822 (approx 86%) pictures for training and 300 (approx 14%) pictures for validation.\n",
    "#We setup the condition that the validation pictures should contain at least one picture per turtle_id for each image_location\n",
    "#as per now we have nothing to avoid having pictures that are very similiar in both datasets, which could result in overfitting the CNN\n",
    "\n",
    "#define the number of validation pictures and the number of training pictures\n",
    "N_val_pics=300\n",
    "N_train_pics=1822\n",
    "\n",
    "#create two empty lists to store the pictures files that are going to be moved to the training \n",
    "#and validation fodlers\n",
    "training_pictures=[]\n",
    "validation_pictures=[]\n",
    "\n",
    "#list to check if combination is already used\n",
    "turtle_id_image_location=[]\n",
    "\n",
    "#loop through each individual turtle_id and secondary image_location\n",
    "for index in range(0, len(train_data)):\n",
    "    if train_data['turtle_id-image_location'][index] not in turtle_id_image_location:\n",
    "        validation_pictures.append(train_data['turtle_id-image_id'][index])\n",
    "        turtle_id_image_location.append(train_data['turtle_id-image_location'][index])\n",
    "    else:\n",
    "        training_pictures.append(train_data['turtle_id-image_id'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f9f35-269b-4bc2-9409-da5bdae28476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if number of validation pictures is indeed 300\n",
    "len(validation_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ad865-1846-48a8-82be-f29f05ca44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534040a7-31e4-449b-bb4d-6cac49128957",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '../cropped_unsorted/'\n",
    "\n",
    "val_images = []\n",
    "train_images = []\n",
    "#loop through the list of pictures\n",
    "#move the pictures files to the validation folder\n",
    "for i in range(0, len(validation_pictures)):\n",
    "    #get the picture name\n",
    "    val_file_name = image_dir + validation_pictures[i].split('-')[-1]\n",
    "    image_name = validation_pictures[i].split('-')[-1]\n",
    "\n",
    "    #create a variable with the directory and the name of the pictures file\n",
    "    output_name_val=root_dir+\"/val/\"+validation_pictures[i].split('-')[-0]+\"/\"+image_name\n",
    "       \n",
    "    #move the file\n",
    "    shutil.copy(val_file_name, output_name_val)\n",
    "    \n",
    "    # put the information into a DataFrame\n",
    "    val_images.append(image_name)\n",
    "\n",
    "for i in range(0, len(training_pictures)):\n",
    "    #get the picture name (e.g. \"01103F7D5A_2018-11-26_07-56-03.jpg\")\n",
    "    train_file_name = image_dir + training_pictures[i].split('-')[-1]\n",
    "    image_name = training_pictures[i].split('-')[-1]\n",
    "\n",
    "    #create a variable with the directory and the name of the pictures file\n",
    "    output_name_train=root_dir+\"/train/\"+training_pictures[i].split('-')[-0]+\"/\"+image_name\n",
    "       \n",
    "    #move the file\n",
    "    shutil.copy(train_file_name, output_name_train)    \n",
    "    \n",
    "    train_images.append(image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1422f0a-492a-4053-9c00-4d36d8a98d93",
   "metadata": {},
   "source": [
    "## Sort test images\n",
    "To appriately use our Train_CNN pipeline, we need to move our test pictures into a subfolder, as well.\n",
    "\n",
    "As we don't know the turtle_id for these pictures, we will save them into subfolders containing their image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675bf922-2200-4051-a326-3b8f32dd5589",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/test_corrected.csv')\n",
    "test_data_jpg = pd.read_csv('../data/test_corrected.csv')\n",
    "test_data_jpg.image_id = test_data_jpg.image_id.apply(lambda x: x.strip()+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6bfd7-2bcb-4e69-bfee-bb9988bc4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the folder were the training and validation datasets will be placed\n",
    "root_dir=\"../cropped_sorted/\"\n",
    "image_dir=\"../cropped_unsorted\"\n",
    "#loop through all individuals and create a folder for the test dataset\n",
    "for i in range(0, len(test_data)):\n",
    "    test_dir_folder= root_dir + \"test/\" + test_data['image_id'][i]#variable with the full path of the training folder\n",
    "    if not os.path.exists(test_dir_folder):#condition for if the folder already exists\n",
    "        os.makedirs(test_dir_folder)#create the folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6a670-3390-46bf-8f45-98afad141e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put images into the folders\n",
    "root_dir=\"../cropped_sorted/\"\n",
    "image_dir=\"../cropped_unsorted/\"\n",
    "\n",
    "for i in range(0, len(test_data)):    \n",
    "    image_name = test_data_jpg['image_id'][i]\n",
    "    test_file_name = image_dir + image_name\n",
    "    output_name = root_dir + \"test/\" + test_data['image_id'][i] + \"/\" + image_name\n",
    "    #move the file\n",
    "    shutil.copy(test_file_name, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04599261-ca25-48b8-96bf-18602485e834",
   "metadata": {},
   "source": [
    "## Create dataframes with new folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86349d-549b-4165-ac9f-0bec901344f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225bc679-5d5a-4fe0-b9fa-6babc56f3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "train_dir=\"../cropped_sorted/train/\"\n",
    "\n",
    "for r, d, f in os.walk(train_dir):\n",
    "    d.sort()\n",
    "    for file in sorted(f):\n",
    "        if \".jpg\" in file:\n",
    "            train.append((d,os.path.join(r,file)))\n",
    "\n",
    "df_train = pd.DataFrame(train,columns=['folder','image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4740611-e867-4531-a857-0257ee57111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "train_dir=\"../cropped_sorted/train/\"\n",
    "\n",
    "for r, d, f in os.walk(train_dir):\n",
    "    d.sort()#key=str.lower)\n",
    "    for file in sorted(f):\n",
    "        if \".jpg\" in file:\n",
    "            train.append((d,os.path.join(r,file)))\n",
    "\n",
    "df_train = pd.DataFrame(train,columns=['folder','image_id'])\n",
    "\n",
    "val = []\n",
    "val_dir=\"../cropped_sorted/val/\"\n",
    "\n",
    "for r, d, f in os.walk(val_dir):\n",
    "    d.sort()#key=str.lower)\n",
    "    for file in sorted(f):\n",
    "        if \".jpg\" in file:\n",
    "            val.append((d,os.path.join(r,file)))\n",
    "\n",
    "df_val = pd.DataFrame(val,columns=['folder','image_id'])\n",
    "\n",
    "test = []\n",
    "val_dir=\"../cropped_sorted/test/\"\n",
    "\n",
    "for r, d, f in os.walk(val_dir):\n",
    "    d.sort()#key=str.lower)\n",
    "    for file in sorted(f):\n",
    "        if \".jpg\" in file:\n",
    "            test.append((d,os.path.join(r,file)))\n",
    "\n",
    "df_test = pd.DataFrame(test,columns=['folder','image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab4536-ba63-4869-b034-1151343cd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train['image_id']\n",
    "df_val = df_val['image_id']\n",
    "df_test = df_test['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8df97-6ad9-4c2d-85a3-c748fd0a8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for line in range(len(df_train)):\n",
    "    train.append(df_train[line][-15:])\n",
    "\n",
    "val = []\n",
    "for line in range(len(df_val)):\n",
    "    val.append(df_val[line][-15:])\n",
    "\n",
    "test = []\n",
    "for line in range(len(df_test)):\n",
    "    test.append(df_test[line][-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e3c8e-7ccc-4c9b-8ab8-06963cf0254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_location_train = []\n",
    "for i in range(len(train)):\n",
    "    for j in range(len(train_data)):\n",
    "        if train[i] in train_data['image_id'][j]: \n",
    "            image_location_train.append(train_data['image_location'][j])\n",
    "            \n",
    "d_train = {'image_id':train,'image_location':image_location_train}   \n",
    "df_train = pd.DataFrame(d_train)\n",
    "df_train.to_csv('../data/cropped_sorted_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607189a-ff92-4632-b5a1-58fbcb2c9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_location_val = []\n",
    "for i in range(len(val)):\n",
    "    for j in range(len(train_data)):\n",
    "        if val[i] in train_data['image_id'][j]: \n",
    "            image_location_val.append(train_data['image_location'][j])\n",
    "            \n",
    "d_val = {'image_id':val,'image_location':image_location_val}   \n",
    "df_val = pd.DataFrame(d_val)\n",
    "df_val.to_csv('../data/cropped_sorted_val.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bf1db-194d-4efe-9639-f8b5b27766ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_location_test = []\n",
    "for i in range(len(test)):\n",
    "    for j in range(len(test_data_jpg)):\n",
    "        if test[i] in test_data_jpg['image_id'][j]: \n",
    "            image_location_test.append(test_data_jpg['image_location'][j])\n",
    "            \n",
    "d_test = {'image_id':test,'image_location':image_location_test}   \n",
    "df_test = pd.DataFrame(d_test)\n",
    "df_test.to_csv('../data/cropped_sorted_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
