{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3308102a-85aa-4bfb-9eb0-f5ebe8a48696",
   "metadata": {},
   "source": [
    "# Train CNN-Model\n",
    "\n",
    "This notebook will train our model based on pictures in our sorted_images folder and sub-folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610afd1-ff7b-40ae-9696-15768d1370ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the modules\n",
    "import keras\n",
    "from keras import models, layers\n",
    "from keras.activations import relu, softmax\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Dense, Flatten, concatenate\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "sys.modules['Image'] = Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6351521-e0a1-487f-8ddb-62c418f9985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras' data generator can be used to pass the images through the convolutional neural network and apply\n",
    "#rotation and zoom transformations to the images. Check https://keras.io/preprocessing/image/ for more transformations\n",
    "\n",
    "train_data = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        zoom_range=0.2,\n",
    "        rescale = 1./255)\n",
    "\n",
    "train_generator = train_data.flow_from_directory(\n",
    "        directory=r\"../sorted_images/train\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1822,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6f3f9-7208-417b-89ee-9b941d07c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the validation data generator\n",
    "val_data = ImageDataGenerator(rescale = 1./255)\n",
    "                                 \n",
    "val_generator = val_data.flow_from_directory(\n",
    "        directory=r\"../sorted_images/val\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=300,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113000c-6950-41bb-8702-f30e5e5871a1",
   "metadata": {},
   "source": [
    "## Getting dummies as arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1623d5-62e8-4592-843d-2f88d8360e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/df_sorted_train.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ee7ca-5557-4efc-8ac2-e018a7911f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[\"image_location\"]\n",
    "train_data_encoded = pd.get_dummies(train_data, columns=[\"image_location\"], drop_first=True)\n",
    "train_data_array = np.array(train_data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6631df7-7964-478e-a0e1-a6fd890a01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('../data/df_sorted_val.csv')\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586669db-1c62-40c5-884e-25f411bf3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data[\"image_location\"]\n",
    "val_data_encoded = pd.get_dummies(val_data, columns=[\"image_location\"], drop_first=True)\n",
    "val_data_array = np.array(val_data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd8b876-160c-447a-9edc-9588ee0475a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same for test data\n",
    "test_data = pd.read_csv('../data/df_sorted_test.csv')\n",
    "test_data = test_data[\"image_location\"]\n",
    "test_data_encoded = pd.get_dummies(test_data, columns=[\"image_location\"], drop_first=True)\n",
    "test_data_array = np.array(test_data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c132cdd-5089-4db6-9bf7-5e31a0f7a8ba",
   "metadata": {},
   "source": [
    "## MLP for classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba105bb4-6559-4845-9ed0-52f4e0ebae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model = Sequential()\n",
    "MLP_model.add(Dense(8, input_dim=train_data_array.shape[1], activation=\"relu\"))\n",
    "MLP_model.add(Dense(12, activation=\"relu\"))\n",
    "MLP_model.add(Dense(12, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a2a9a-994a-4bec-ad89-c7aceb5994c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33551e3-9186-4176-815d-5a5e509f0efe",
   "metadata": {},
   "source": [
    "## CNN Network for Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ff883-d569-4ac7-ba88-cd5707556122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pre-trained VGG19 from keras\n",
    "vgg19 = VGG19(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
    "cnn_model = vgg19.layers[-1].output\n",
    "#add dropout and the fully connected layer\n",
    "cnn_model = layers.Dropout(0.5)(cnn_model)\n",
    "cnn_model = layers.Flatten()(cnn_model)\n",
    "cnn_model = layers.Dense(256, activation='relu')(cnn_model)\n",
    "\n",
    "cnn = Model(vgg19.input, cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efbca5-bbbe-4b24-8c94-5a917c4d25b3",
   "metadata": {},
   "source": [
    "## Multi-input / Concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4796e-f762-4ccc-97d5-5d0bc2c52f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the input to our final set of layers as the *output* of both\n",
    "# the MLP and CNN\n",
    "combinedInput = concatenate([MLP_model.output, cnn.output])\n",
    "\n",
    "predictors = Dense(100, activation='softmax')(combinedInput)\n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "combined_model = Model(inputs=[MLP_model.input, cnn.input], outputs=predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad3b8e-77e2-401d-81b0-d092bc0b8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "combined_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5),#define the optimizer and the learning rate\n",
    "              metrics=tf.keras.metrics.TopKCategoricalAccuracy(k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4896ce1-01c9-4714-9d1e-3a6766605741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where to save the model after each epoch\n",
    "filepath = \"../models/Saved_model_concatenation.h5\"\n",
    "# add a critera to save only if there was an improvement in the model comparing\n",
    "# to the previous epoch (in this caset the model is saved if there was a decrease in the loss value)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# stop training if there is no improvement in model for 3 consecutives epochs.\n",
    "early_stopping_monitor = EarlyStopping(patience=15)\n",
    "callbacks_list = [checkpoint, early_stopping_monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290f995-e4b4-41b8-a704-7b2817b89ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting arrays for the images and labels\n",
    "x_train, y_train=next(train_generator)\n",
    "x_val, y_val=next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296f631-4bd1-45df-80ce-9627eda41b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c2a2c-505a-401e-ae34-2ce7df060ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "batch_size=32\n",
    "model_history=combined_model.fit(\n",
    "        [train_data_array, x_train], y_train,\n",
    "        steps_per_epoch=1822 //batch_size,#number of pictures in training data set divided by the batch size\n",
    "        epochs=30,\n",
    "        validation_data=([val_data_array, x_val], y_val),\n",
    "        validation_steps= 300 // batch_size,#number of pictures in validation data set divided by the batch size\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb518d3-c0f0-497e-835b-aefc44a0426e",
   "metadata": {},
   "source": [
    "## Convolutional neural network without concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264bb18-041e-4672-be30-1734b248bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pre-trained VGG19 from keras\n",
    "vgg19 = VGG19(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
    "x = vgg19.layers[-1].output\n",
    "#add dropout and the fully connected layer\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "#add a dense layer with a value equal to the number of classes\n",
    "predictors = Dense(101, activation='softmax')(x)\n",
    "# Create the model\n",
    "vgg19model = Model(vgg19.input, predictors)\n",
    "\n",
    "vgg19model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ea324-fdf3-47a3-b1ad-997e00fe70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the model\n",
    "#vgg19model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652874f-c66e-4a3b-b673-0778e7985d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where to save the model after each epoch\n",
    "filepath = \"../models/Saved_model.h5\"\n",
    "# add a critera to save only if there was an improvement in the model comparing\n",
    "# to the previous epoch (in this caset the model is saved if there was a decrease in the loss value)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# stop training if there is no improvement in model for 3 consecutives epochs.\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "callbacks_list = [checkpoint, early_stopping_monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49174dd4-0105-46e8-9464-6d3dcc38cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "vgg19model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5),#define the optimizer and the learning rate\n",
    "              metrics=tf.keras.metrics.TopKCategoricalAccuracy(k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1696c5-4663-496b-b2b8-37c28773dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "batch_size=32\n",
    "model_history=vgg19model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=10932//batch_size,#number of pictures in training data set divided by the batch size\n",
    "        epochs=30,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps= 300// batch_size,#number of pictures in validation data set divided by the batch size\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dedafa-588d-4194-b009-ff1630d548f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model=load_model(\"../models/Saved_model.h5\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=SGD(lr=1e-6),\n",
    "             metrics=tf.keras.metrics.TopKCategoricalAccuracy(k=5))\n",
    "#train the model\n",
    "batch_size=32\n",
    "model_history_2=model.fit_generator(\n",
    "        train_generator,\n",
    "    #! BEWARE: steps_per_epoch needs to be adapted: containing number of images in train // batch_size\n",
    "        steps_per_epoch=10932//batch_size,\n",
    "        epochs=20,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps= 300// batch_size,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b38eb-00c2-4aab-b629-1a3e668fe676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of the plots\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "columns = 2\n",
    "rows = 1\n",
    "\n",
    "#plot loss\n",
    "#the accuracy and loss are stored in the \"model_history\"\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.plot(model_history.history['loss']+ model_history_2.history['loss']) #merge the loss from the two training steps\n",
    "plt.plot(model_history.history['val_loss']+ model_history_2.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "#plot accuracy\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.plot(model_history.history['acc']+ model_history_2.history['acc'])\n",
    "plt.plot(model_history.history['val_acc']+ model_history_2.history['val_acc'])\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba568e-aa6f-4568-a1c4-2207ab82b957",
   "metadata": {},
   "source": [
    "### Testing the model + submission\n",
    "\n",
    "Prepare the data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1acc3f-db95-4678-9487-692dde87b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the best saved trained model\n",
    "model=load_model(\"../models/Saved_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d926b5-64f6-4a8d-bf3d-78bf2dfd6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sony_datagen1 = ImageDataGenerator(rescale = 1./255)\n",
    "val_sony_datagen = val_sony_datagen1.flow_from_directory(\n",
    "        directory=\"../sorted_images/test\", #This folder should contain pictures of each bird in a different subfolder (similar to the training data set)\n",
    "        target_size=(224, 224),\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=490, #number of images in the testing dataset\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cccd0cf-fefc-4272-9f1e-52906640bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pictures in the testing folder. The x_batch contains the pictures and the y_batch contains the\n",
    "#identities of the individuals\n",
    "x_batch, y_batch=next(val_sony_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0fec8-3b3d-48ca-8d84-5a1c7fe306d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6da8f7-0460-4586-84fb-92421d66d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_index = []\n",
    "predictions_probabilities = []\n",
    "results = []\n",
    "\n",
    "#for i in range(0,len(x_batch)):\n",
    "for i in range(0,len(x_batch)):    \n",
    "    probabilities_sorted = []\n",
    "    index_sorted = [] \n",
    "    image=np.expand_dims(x_batch[i], axis=0)\n",
    "    result=model.predict(image)\n",
    "    results.append(result)\n",
    "    y_preds_indices = np.argsort(result)[:,-5:]\n",
    "    top_5_values = [result[0][j] for j in y_preds_indices]\n",
    "    \n",
    "    for index in range(1,6):\n",
    "        probabilities_sorted.append(top_5_values[0][-index])\n",
    "        index_sorted.append(y_preds_indices[0][-index])\n",
    "    predictions_probabilities.append(probabilities_sorted)\n",
    "    predictions_index.append(index_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f93c3-0d96-4c24-9ab9-e340ca7497ec",
   "metadata": {},
   "source": [
    "## Prediction for concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e2b335-e5d3-4c47-b8b7-a465c3208391",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.save('combined_model_epoch16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc9f36-73cc-4bd8-927b-2b63bdc22dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model=load_model(\"combined_model_epoch16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60386270-84b2-4ad2-9b9e-6a7fda39416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model=load_model(\"../models/Saved_model_concatenation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de9998-1df5-4d64-8f29-71e45e935f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=combined_model.predict([test_data_array, x_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b9796-63af-4443-9976-bb56ddb7ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_index = []\n",
    "predictions_probabilities = []\n",
    "result = []\n",
    "\n",
    "for i in range(0,len(x_batch)):    \n",
    "    probabilities_sorted = []\n",
    "    index_sorted = [] \n",
    "    result = results[i]\n",
    "    y_preds_indices = np.argsort(result)[-5:]\n",
    "    top_5_values = [results[j] for j in y_preds_indices]\n",
    "    for index in range(1,6):\n",
    "        probabilities_sorted.append(top_5_values[-index])\n",
    "        index_sorted.append(y_preds_indices[-index])\n",
    "    predictions_probabilities.append(probabilities_sorted)\n",
    "    predictions_index.append(index_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73fdafb-0065-4a83-80d9-217c490810ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702083ea-8195-4ff7-bf52-47ae441bd343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#This code creates a new predictions_indices list with taking:\n",
    "# If first and second probabilities have a difference more than 80%, take only first prediction for top5\n",
    "# If two probabilities differ more than 50%, take the higher probability thrice\n",
    "# If two probabilities differ more than 20%, take the higher probability twice\n",
    "\n",
    "new_predictions_indices = []\n",
    "for i in range(0,len(predictions_probabilities)):   \n",
    "    list = []\n",
    "    j = 0\n",
    "    numbers_taken = 0\n",
    "    while j < 4 and numbers_taken < 4:\n",
    "        if predictions_probabilities[i][j] < 0.03:\n",
    "            list.append(100)\n",
    "            j = j + 1\n",
    "            numbers_taken = numbers_taken + 1\n",
    "        \n",
    "        elif predictions_probabilities[i][j] - predictions_probabilities[i][j+1] > 0.8:\n",
    "            for times in range(5):\n",
    "                list.append(predictions_index[i][j])\n",
    "            j = j + 5\n",
    "            numbers_taken = numbers_taken + 5\n",
    "            \n",
    "        elif predictions_probabilities[i][j] - predictions_probabilities[i][j+1] > 0.5 and numbers_taken < 3:\n",
    "            for times in range(3):\n",
    "                list.append(predictions_index[i][j])\n",
    "            j = j + 1\n",
    "            numbers_taken = numbers_taken + 3\n",
    "            \n",
    "        elif predictions_probabilities[i][j] - predictions_probabilities[i][j+1] > 0.2 and numbers_taken < 4:\n",
    "            for times in range(2):\n",
    "                list.append(predictions_index[i][j])\n",
    "            j = j + 1\n",
    "            numbers_taken = numbers_taken + 2\n",
    "            \n",
    "        elif numbers_taken < 4:\n",
    "            list.append(predictions_index[i][j])\n",
    "            j = j + 1\n",
    "            numbers_taken = numbers_taken + 1\n",
    "        else:\n",
    "            j = j + 1\n",
    "    if numbers_taken < 5:\n",
    "        if predictions_probabilities[i][j] < 0.03:\n",
    "            list.append(100)\n",
    "        else:\n",
    "            list.append(predictions_index[i][j])\n",
    "    new_predictions_indices.append(list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706aa8d9-d088-43de-955a-13a691295bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create labels to connect indices with turtle_ids (folder structure in train)\n",
    "labels = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61314e-0706-4832-a27d-1473bf65d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if labels contains anything which is not correct, e.g. .ipynb_checkpoints\n",
    "#The correct order would be as order of sub-folders in \"sorted_images/train\"\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2942b0-87ae-4b94-bc2b-3499fff871fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c80a55-a49f-4115-b85a-4991fbf25bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe for image_ids in order of validation generator (folder structure in val)\n",
    "images_ids = list(val_sony_datagen.class_indices.keys())\n",
    "titles = ['image_id']\n",
    "test_data = pd.DataFrame(images_ids,columns=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160d029-eead-462d-b2b0-eb90b7786307",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a8892-ccc6-471e-b079-f468976529d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv('../data/train_corrected.csv')\n",
    "#unique_turtle_ids = list(train_data['turtle_id'].unique())\n",
    "\n",
    "list = []\n",
    "array = []\n",
    "for line in predictions_index:\n",
    "    for id in line:\n",
    "        list.append(labels[id])\n",
    "    array.append(list)\n",
    "    list = []\n",
    "    \n",
    "titles = ['prediction1', 'prediction2','prediction3','prediction4','prediction5']\n",
    "submission = pd.DataFrame(array, columns= titles)\n",
    "\n",
    "#Insert image_ids from test_data\n",
    "\n",
    "submission.insert(loc=0, column='image_id', value=test_data['image_id'])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d14679-0382-42fc-bee4-37806908946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586af11-99be-4fd1-9e6d-da8ca82d415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save submission data as CSV\n",
    "submission.to_csv('../data/submission_concatenationvs4.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a1df1-a6b8-4e11-b28c-44409ca928cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random list for submission\n",
    "\n",
    "If you want to compare the results with random turtles, use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aba4f5-4217-4f1a-aaad-2d0d414a949d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865f419-e274-4ea1-8e4b-a417387a00a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list = []\n",
    "predictions_index = []\n",
    "for line in range(0,490):\n",
    "    for number in range(0,5):\n",
    "        list.append(random.randint(0,99))\n",
    "    predictions_index.append(list)\n",
    "    list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35af9c8-7147-4ba7-820b-e5b7f83186b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "array = []\n",
    "for line in predictions_index:\n",
    "    for id in line:\n",
    "        list.append(labels[id])\n",
    "    array.append(list)\n",
    "    list = []\n",
    "    \n",
    "titles = ['prediction1', 'prediction2','prediction3','prediction4','prediction5']\n",
    "submission = pd.DataFrame(array, columns= titles)\n",
    "\n",
    "#Insert image_ids from test_data\n",
    "test_data = pd.read_csv(images_ids)\n",
    "submission.insert(loc=0, column='image_id', value=test_data['image_id'])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872cc7d-0bd1-4068-9229-553e58716abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save submission data as CSV\n",
    "submission.to_csv('../data/submission_random.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
