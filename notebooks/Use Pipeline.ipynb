{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6e27b1-188a-4afb-98f9-38818e508f23",
   "metadata": {},
   "source": [
    "# Image Modelling Part 2 - Use Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159167b4-2c3d-4c4d-9f75-2cd5462277c6",
   "metadata": {},
   "source": [
    "In the first notebook we used shell commands to prepare and split our data into a train and evaluation set. \n",
    "Furthermore, we defined some functions that will allow us to directly import our pictures and the corresponding class labels and if we want to also augment our data. \n",
    "Now, we will import the functions from the `image_modelling.py` file and use them to facilitate the data preparation step in this notebook. \n",
    "Lastly, we will use Tensorflow and Keras to create and train our neuronal network to identify turtles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118d51-c16b-4c7f-a6bf-6276f7a7c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "import tensorflow as tf\n",
    "import image_modeling   # import image_modeling.py file\n",
    "import tensorflow_hub as hub\n",
    "import datetime\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387f387-ca7d-4679-a05e-f92de2e9177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559448f7-019f-4047-901c-b477cd27e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Tensorflow version\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1bb25-2f7f-479e-9aeb-fd56f13b9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import variables from image_modelling.py file\n",
    "HEIGHT = image_modeling.HEIGHT\n",
    "WIDTH = image_modeling.WIDTH\n",
    "NCLASSES = image_modeling.NCLASSES\n",
    "CLASS_NAMES = image_modeling.CLASS_NAMES\n",
    "BATCH_SIZE = image_modeling.BATCH_SIZE\n",
    "TRAINING_SIZE = !wc -l < ../data/train_noheader_split.csv\n",
    "go_trough_per_epoch = int(2)\n",
    "TRAINING_STEPS = (int(TRAINING_SIZE[0]) // BATCH_SIZE) * go_trough_per_epoch\n",
    "\n",
    "TRAIN_PATH = '../data/train_noheader_split.csv'\n",
    "EVAL_PATH = '../data/test_noheader_split.csv'\n",
    "TEST_PATH = '../data/test_noheader_split.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b00031-663c-4004-bf86-4b64e6cd6e5a",
   "metadata": {},
   "source": [
    "Double check if the variables now contain the correct values. ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07961c12-db7b-402e-adfa-5e55ae4cb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can compare this output with the variables in the image_modelling.py file...\n",
    "print(HEIGHT)\n",
    "print(CLASS_NAMES)\n",
    "print(NCLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bda7a2-6102-4eff-93b9-e9b74e6cd405",
   "metadata": {},
   "source": [
    "## Building our Model\n",
    "\n",
    "Building and training a neural network involves various steps: \n",
    "1. define the architecture of the model\n",
    "2. compile the model\n",
    "3. train the model\n",
    "4. evaluate the model\n",
    "\n",
    "We have to start with defining the architecture. Our neural network will consist of several layers that are chained together. The input layer of our model will take our input data and hand it over to the flatten layer, which is responsible for reformatting our data. It will transform the format of our images from a three-dimensional array (HEIGHT, WIDTH, 3) to a one-dimensional array of size HEIGHT * WIDTH * 3. \n",
    "After the pixels are flattened we use a dense layer that returns a logits array with length `NCLASSES`. Each node in this layer contains a score that indicates the current image belongs to one of the n classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf568e1-d651-47ba-a15f-a4fa901170bc",
   "metadata": {},
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c3f1e-f4cd-4f1e-9abb-4c49c2205ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a simple linear model.\n",
    "def linear_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[HEIGHT, WIDTH, 3], name='image'))\n",
    "    model.add(tf.keras.layers.Flatten(data_format=\"channels_last\"))\n",
    "    # We want to have a simple linear model so we have \n",
    "    # no activation function. \n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c74046-b4ed-42ec-9816-4ad3f68a74a4",
   "metadata": {},
   "source": [
    "Before we can train our model we need to compile it and define more settings. We have to choose a loss function, an optimizer and metrics. \n",
    "* The **loss function** measures how accurate the model is during training by calculating the model error. Usually we want to minimize this function to improve our model. As you can see in the [TensorFlow documentation](https://www.tensorflow.org/api_docs/python/tf/keras/losses) there are lot's of different loss functions to choose from. Some, e.g. the mean squared errror, hopefully look familiar to you. ;) \n",
    "* The **[optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)** defines how the model is updated based on the data and the loss function. One optimizer we've already covered earlier and which is also used for neural networks is the stochastic gradient descent (SGD) algorithm.   \n",
    "* The **metric** is used to monitor the training process. Here we can choose one of the metrics we've already encountered or [many more](https://www.tensorflow.org/api_docs/python/tf/keras/metrics). \n",
    "\n",
    "The following function compiles our model, loads the data using the `load_dataset()` function from the image_modelling.py file and trains the model on the loaded data. In the end the function returns our fitted model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea0e7a-60e1-405f-9b16-1fd512965815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for training and evaluation\n",
    "def train_and_evaluate(model, batch_size):\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        # The model outputs one-hot-encoded logits, so we need\n",
    "        # use the sparse version of the crossentropy loss.\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    dataset = image_modeling.load_dataset(TRAIN_PATH, batch_size)\n",
    "    eval_dataset = image_modeling.load_dataset(EVAL_PATH, batch_size, training=False)\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model.fit(\n",
    "        dataset, \n",
    "        validation_data=eval_dataset,\n",
    "        steps_per_epoch=TRAINING_STEPS, \n",
    "        epochs=10,\n",
    "        callbacks=[tensorboard_callback]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fdebe-9f42-4061-ac71-d5d4ad7f0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train our model using the prior defined functions \n",
    "model = linear_model()\n",
    "trained_model = train_and_evaluate(model, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56088167-b93d-4639-ac63-40255d0e6ca8",
   "metadata": {},
   "source": [
    "Let us use Tensorboard to monitor our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b04f0c-1e01-4539-8771-ecd56286261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81df32d-435f-4213-a159-68e7035787a5",
   "metadata": {},
   "source": [
    "Since we worked entirely with functions so far, we will also define one for testing our model. The function will load our test data and use it in order to evaluate the performance of our model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161a0e5-46ca-421a-8ba1-3f7b49234292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a testing function.\n",
    "def test(model):\n",
    "    \n",
    "    test_dataset = image_modeling.load_dataset(TEST_PATH, batch_size=1, training=False)\n",
    "    model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f9b76-3d46-42bf-bee0-648d6525e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the testing function for our model\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8a69c-781d-41fc-8a4b-6f2d1b2de1bb",
   "metadata": {},
   "source": [
    "### Deep Neural Network\n",
    "\n",
    "Our simple model is not performing well. Maybe we can boost its performance by adding more layers.\n",
    "\n",
    "In the following `dnn_model()` function we add three more hidden, dense layers after the flatten layer to increase our models complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98cfb8-748e-43d4-bace-3af0733d2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets compare a neural network with hidden layers to the linear model\n",
    "def dnn_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[HEIGHT, WIDTH, 3], name='image'))\n",
    "    model.add(tf.keras.layers.Flatten(data_format=\"channels_last\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 40, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 40, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 30, activation = \"relu\"))\n",
    "    # We want to have a simple linear model so we have \n",
    "    # no activation function. \n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97794117-9aee-4fda-a85c-4b513dd9575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us fit the deep neural network\n",
    "model = dnn_model()\n",
    "trained_model = train_and_evaluate(model, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c0148-7d2d-4a11-9441-65639369aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383dc998-8c17-4195-9ea2-016cd783ce14",
   "metadata": {},
   "source": [
    "Adding more hidden layers to our model, did indeed increase the accuracy. But still, the model's performance leaves something to be desired. Since we are working with images, switching to a convolutional neural network might help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f44d66-bc7c-4ea5-9d40-0234126ba2f1",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "CNN's are widely used for image recognition. They are regularized versions of DNN's able to be deeper without generating as much parameters due to its [convolutional](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/) and pooling layers.\n",
    "\n",
    "The architecture of our CNN is even more complex. This time we combine dense layers with `Conv2D` and `MaxPooling2D` layers. The convolutional and max pooling layers are inserted between the input layer and the flatten layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4670c8-ad93-4533-a1da-0c158e9f32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us move on to a CNN model. \n",
    "def cnn_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[HEIGHT, WIDTH, 3], name='image'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=10, kernel_size=[5, 5], padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=[5, 5], padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=300, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15784cd7-83e1-450d-a4c4-a1c2d8bfb64d",
   "metadata": {},
   "source": [
    "We can have a look at the architecture of our model with the method `.summary`. As you can see in the summary below, the output of each `Conv2D` and `MaxPooling2D` layer is also a three dimensional tensor of shape (height, width, channels). As we go deeper into the network the dimensions shrink. One advantage of the shrinking dimensions is that we can computationally afford to add more output channels in each convolutional layer. We can control the number of the output channels of those layers with the `filters` argument. \n",
    "\n",
    "However, at the end of our model we still need the combination of the flatten and dense layers to perform classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231a24d-56dc-4019-aa5a-b0bde1e6f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814fc79-a858-4c48-a582-0ea8996cb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us fit the convolutional neural network\n",
    "model = cnn_model()\n",
    "trained_model = train_and_evaluate(model, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc98fdf-e19e-409a-be68-31814562eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783eea5c-83af-40f1-8410-aebdbdcaa013",
   "metadata": {},
   "source": [
    "We see the CNN give better results than the DNN. But we still have heavy overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f652f9-4e89-4782-a2d5-c3b5c156adf0",
   "metadata": {},
   "source": [
    ">__Exercise__: try to reduce overfitting of your model by: \n",
    "- making full use of your data augmentation by increasing `steps_per_epoch` in the `train_and_evaluate` function.\n",
    "- [adding regularization](https://keras.io/api/layers/regularizers/) to the `Conv2D` and `Dense` layers.\n",
    "- Adding dropout layers. See section CNN Dropout Regularization of [this](https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/)\n",
    "\n",
    "You can also try adding additional `Conv2D`, `MaxPooling2D` or `Dense` layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc42e33-a846-43dc-92bb-8a4fd3a5f125",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Transfer learning is when a model is trained on one task and is then reused for another task. One approach to transfer learning is fine-tuning. Here you take a trained neural net, exchange the last layer (head) for another layer, that fits the new task and then train the weights of the last layer only. \n",
    "\n",
    "First we need to download the headless model (this can take a while) we use MobileNetV2 which is a CNN that was trained on the [ImageNet](https://en.wikipedia.org/wiki/ImageNet) dataset, consisting of over 14 million images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53795c-03bb-4aae-955c-2ecd4ce3ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,input_shape=(HEIGHT,WIDTH,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d37d23-a8c8-481c-bc07-b24dec923217",
   "metadata": {},
   "source": [
    "We only want to train the last layer therefore we freeze the layers of our headless model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd5b0b4-53c8-4d0f-9ea0-a3b2fff80779",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098ce17-6fe8-4f30-a378-5961b7e714e6",
   "metadata": {},
   "source": [
    "Now we define our model by simply adding the output layer to our pretrained net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93b6e1-e8ce-4202-8351-94be03fbda34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_learning_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(feature_extractor_layer)\n",
    "    # TODO: add the correct output layer here\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=300, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211eae9-746e-4f39-a10b-d4d802538955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us fit our transfer learning model\n",
    "model = transfer_learning_model()\n",
    "trained_model = train_and_evaluate(model, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3232d-a28c-411b-bcb3-afe050c5a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d255ce-6a71-49a7-a0d0-48412f4e9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde9b069-d2b8-4a31-bc4c-3b66550b9479",
   "metadata": {},
   "source": [
    "As we see the results of fine-tuning surpass the results of the linear model, DNN and CNN. Fine-tuning is a very powerful approach which can generalize well even with limited amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87104bb2-0a25-47df-9545-d75204a99530",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "We trained our different model architectures linear, DNN, CNN, and fine-tuned MobileNetV2. With increasing complexity of the model (number of parameters) the results get better but also overfitting is more of an issue. Because with lots of parameters and not so much images the NN can memorize each image in the train set without learning more general features. You tried out different ways to counteract overfitting:\n",
    "- Training on more data. Data augmentation is a way to generate more data and therefore helps. \n",
    "- Using a CNN architecture. The CNN's convolutional and max pooling layers reduce the number of parameters allowing the network to be deeper. Leading to less overfitting.\n",
    "- L1 or L2 Regularization is another possibility to deal with overfitting.\n",
    "- Adding dropout layers. Helps prevent [co-adapting](https://machinelearning.wtf/terms/co-adaptation/) and overfitting.\n",
    "\n",
    "Finally you used a pretrained CNN with fine-tuning to utilize the power of a network trained on over 14 million images. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caebcfe-6dfa-4006-8ec0-18534b1f3748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
