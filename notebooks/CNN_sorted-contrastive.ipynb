{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719fc9fa-ca52-432a-9148-b156ccd51600",
   "metadata": {},
   "source": [
    "# Train Contrastive Learning CNN-Model\n",
    "\n",
    "This notebook will train our model based on pictures in our sorted_images folder and sub-folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8b2c4-61be-488b-b764-2f4241e20b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d6f5c8-da50-498a-8464-6e795523f78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobiasengbring/neuefische/Capstone_Project_Turtle_Recall/.venv/lib/python3.9/site-packages/jax/_src/lib/__init__.py:32: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "#load the modules\n",
    "import keras\n",
    "import random\n",
    "from keras import models, layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.losses import ContrastiveLoss\n",
    "from keras.activations import relu, softmax\n",
    "from tensorflow.keras.applications import VGG19, ResNet50V2\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Dense, Flatten, concatenate\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "sys.modules['Image'] = Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd44f886-57db-42cf-a4ff-9d38692cfe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1825 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "# Keras' data generator can be used to pass the images through the convolutional neural network and apply\n",
    "#rotation and zoom transformations to the images. Check https://keras.io/preprocessing/image/ for more transformations\n",
    "\n",
    "train_data = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        rotation_range=40,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        #fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_data.flow_from_directory(\n",
    "        directory=r\"../sorted_images/train\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1822,\n",
    "        class_mode='sparse',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b3a8394-2e5a-41e2-967d-3e196cd8cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "#defining the validation data generator\n",
    "val_data = ImageDataGenerator(rescale = 1./255)\n",
    "                                 \n",
    "val_generator = val_data.flow_from_directory(\n",
    "        directory=r\"../sorted_images/val\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=300,\n",
    "        class_mode='sparse',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480f505d-04cb-468a-8248-67684ee40d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 491 images belonging to 490 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        directory=\"../sorted_images/test\", #This folder should contain pictures of each bird in a different subfolder (similar to the training data set)\n",
    "        target_size=(224, 224),\n",
    "        class_mode='sparse',\n",
    "        batch_size=490, #number of images in the testing dataset\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d988adc-7438-4c91-874e-a6c36bb65df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1822, 224, 224, 3) - y_train shape: (1822,)\n",
      "x_val shape: (300, 224, 224, 3) - y_val shape: (300,)\n",
      "x_test shape: (490, 224, 224, 3) - y_test shape: (490,)\n"
     ]
    }
   ],
   "source": [
    "# Load the train and test data splits\n",
    "x_train, y_train  = next(train_generator)\n",
    "x_val, y_val  = next(val_generator)\n",
    "x_test, y_test = next(test_generator)\n",
    "\n",
    "# Display shapes of train and test datasets\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape} - y_val shape: {y_val.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb5c0e54-318f-49b6-a7b0-88d0db014627",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")\n",
    "x_val = x_val.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ab5e83-ae76-4d71-93a7-15807fc4e011",
   "metadata": {},
   "source": [
    "## Define model for contrastive learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62b65fba-7957-4850-aafb-6b02ff48b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 64\n",
    "margin = 1  # Margin for constrastive loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8583bdc1-c180-4d4d-9644-364ae6b45264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(x, y):\n",
    "    \"\"\"Creates a tuple containing image pairs with corresponding label.\n",
    "\n",
    "    Arguments:\n",
    "        x: List containing images, each index in this list corresponds to one image.\n",
    "        y: List containing labels, each label with datatype of `int`.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing two numpy arrays as (pairs_of_samples, labels),\n",
    "        where pairs_of_samples' shape is (2len(x), 2,n_features_dims) and\n",
    "        labels are a binary array of shape (2len(x)).\n",
    "    \"\"\"\n",
    "\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    #pairs_indices = []\n",
    "    \n",
    "    for idx1 in range(len(x)):\n",
    "        x1 = x[idx1]\n",
    "        label1 = int(y[idx1])\n",
    "        \n",
    "        for idx2 in range(len(x)):\n",
    "            if idx2 > idx1:\n",
    "                x2 = x[idx2]\n",
    "                label2 = int(y[idx2])\n",
    "                #pairs_indices += [[idx1, idx2]]\n",
    "                pairs += [[x1, x2]]\n",
    "            \n",
    "                #Check, if it is a matching example (1) or not (0)\n",
    "                if label1 == label2:\n",
    "                    labels += [1]\n",
    "                else:\n",
    "                    labels += [0]\n",
    "                                  \n",
    "    return np.array(pairs), np.array(labels).astype(\"float32\"), np.array(pairs_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665cf90-b9f2-42e8-b801-d7708bf0a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train, pairs_indices_train = make_pairs(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec738f8-0e03-4f12-afdf-db6157949766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make validation pairs\n",
    "pairs_val, labels_val, pairs_indices_val = make_pairs(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136aaa56-0f3e-4a46-989f-ff2849b876a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pairs_indices_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpairs_indices_val\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pairs_indices_val' is not defined"
     ]
    }
   ],
   "source": [
    "pairs_indices_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ea390-a1c8-4f96-b25a-387b6845b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = pairs_train[:, 0]  # x_train_1.shape is (60000, 28, 28)\n",
    "x_train_2 = pairs_train[:, 1]\n",
    "\n",
    "x_val_1 = pairs_val[:, 0]  # x_val_1.shape = (60000, 28, 28)\n",
    "x_val_2 = pairs_val[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5492d-df25-4d9c-995f-23e5ab888380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(pairs, labels, to_show=6, num_col=3, predictions=None, test=False):\n",
    "    \"\"\"Creates a plot of pairs and labels, and prediction if it's test dataset.\n",
    "\n",
    "    Arguments:\n",
    "        pairs: Numpy Array, of pairs to visualize, having shape\n",
    "               (Number of pairs, 2, 28, 28).\n",
    "        to_show: Int, number of examples to visualize (default is 6)\n",
    "                `to_show` must be an integral multiple of `num_col`.\n",
    "                 Otherwise it will be trimmed if it is greater than num_col,\n",
    "                 and incremented if if it is less then num_col.\n",
    "        num_col: Int, number of images in one row - (default is 3)\n",
    "                 For test and train respectively, it should not exceed 3 and 7.\n",
    "        predictions: Numpy Array of predictions with shape (to_show, 1) -\n",
    "                     (default is None)\n",
    "                     Must be passed when test=True.\n",
    "        test: Boolean telling whether the dataset being visualized is\n",
    "              train dataset or test dataset - (default False).\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define num_row\n",
    "    # If to_show % num_col != 0\n",
    "    #    trim to_show,\n",
    "    #       to trim to_show limit num_row to the point where\n",
    "    #       to_show % num_col == 0\n",
    "    #\n",
    "    # If to_show//num_col == 0\n",
    "    #    then it means num_col is greater then to_show\n",
    "    #    increment to_show\n",
    "    #       to increment to_show set num_row to 1\n",
    "    num_row = to_show // num_col if to_show // num_col != 0 else 1\n",
    "\n",
    "    # `to_show` must be an integral multiple of `num_col`\n",
    "    #  we found num_row and we have num_col\n",
    "    #  to increment or decrement to_show\n",
    "    #  to make it integral multiple of `num_col`\n",
    "    #  simply set it equal to num_row * num_col\n",
    "    to_show = num_row * num_col\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(5, 5))\n",
    "    for i in range(to_show):\n",
    "\n",
    "        # If the number of rows is 1, the axes array is one-dimensional\n",
    "        if num_row == 1:\n",
    "            ax = axes[i % num_col]\n",
    "        else:\n",
    "            ax = axes[i // num_col, i % num_col]\n",
    "\n",
    "        ax.imshow(tf.concat([pairs[i][0], pairs[i][1]], axis=1), cmap=\"gray\")\n",
    "        ax.set_axis_off()\n",
    "        if test:\n",
    "            ax.set_title(\"True: {} | Pred: {:.5f}\".format(labels[i], predictions[i][0]))\n",
    "        else:\n",
    "            ax.set_title(\"Label: {}\".format(labels[i]))\n",
    "    if test:\n",
    "        plt.tight_layout(rect=(0, 0, 1.9, 1.9), w_pad=0.0)\n",
    "    else:\n",
    "        plt.tight_layout(rect=(0, 0, 1.5, 1.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7dd203-8162-4926-8ff1-67d61f10a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(pairs_train[:-1], labels_train[:-1], to_show=4, num_col=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d9ec8b-3eae-4c91-9402-faef30f12d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(pairs_val[:-1], labels_val[:-1], to_show=4, num_col=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50705961-550e-4ef1-9af8-10ef24d40bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided two tensors t1 and t2\n",
    "# Euclidean distance = sqrt(sum(square(t1-t2)))\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "\n",
    "input = layers.Input((224, 224, 3))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = layers.Conv2D(4, (5, 5), activation=\"tanh\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(16, (5, 5), activation=\"tanh\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "\n",
    "'''\n",
    "input = layers.Input((224, 224, 3))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "\n",
    "x = VGG19(input_shape=(224,224,3), weights='imagenet', include_top=False)(x)\n",
    "\n",
    "x.trainable = False\n",
    "'''\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = layers.Dense(1000, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(1000, activation=\"relu\")(x)\n",
    "embedding_network = keras.Model(input, x)\n",
    "\n",
    "input_1 = layers.Input((224, 224, 3))\n",
    "input_2 = layers.Input((224, 224, 3))\n",
    "\n",
    "# As mentioned above, Siamese Network share weights between\n",
    "# tower networks (sister networks). To allow this, we will use\n",
    "# same embedding network for both tower networks.\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1fee7f-45ac-41f4-ab30-0bc673d80e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "  Arguments:\n",
    "      margin: Integer, defines the baseline for distance for which pairs\n",
    "              should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "  Returns:\n",
    "      'constrastive_loss' function with data ('margin') attached.\n",
    "  \"\"\"\n",
    "\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        \"\"\"Calculates the constrastive loss.\n",
    "\n",
    "      Arguments:\n",
    "          y_true: List of labels, each label is of type float32.\n",
    "          y_pred: List of predictions of same length as of y_true,\n",
    "                  each label is of type float32.\n",
    "\n",
    "      Returns:\n",
    "          A tensor containing constrastive loss as floating point value.\n",
    "      \"\"\"\n",
    "\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aceece-49d9-4dd1-8c39-db71ec8192d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where to save the model after each epoch\n",
    "filepath = \"../models/contrastive_model.h5\"\n",
    "# add a critera to save only if there was an improvement in the model comparing\n",
    "# to the previous epoch (in this caset the model is saved if there was a decrease in the loss value)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# stop training if there is no improvement in model for 4 consecutives epochs.\n",
    "early_stopping_monitor = EarlyStopping(patience=4)\n",
    "callbacks_list = [checkpoint, early_stopping_monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf2c05-a7fa-46d4-a96b-1004f59d1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ad04c-fb0f-4ef9-abb7-308375a77167",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = siamese.fit(\n",
    "    [x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2863c85-fc23-48d0-b752-32827375b1e2",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408fd00-1c3d-4932-b811-71d31bfad033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_metric(history, metric, title, has_valid=True):\n",
    "    \"\"\"Plots the given 'metric' from 'history'.\n",
    "\n",
    "    Arguments:\n",
    "        history: history attribute of History object returned from Model.fit.\n",
    "        metric: Metric to plot, a string value present as key in 'history'.\n",
    "        title: A string to be used as title of plot.\n",
    "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.plot(history[metric])\n",
    "    if has_valid:\n",
    "        plt.plot(history[\"val_\" + metric])\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot the accuracy\n",
    "plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")\n",
    "\n",
    "# Plot the constrastive loss\n",
    "plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52dba6c-fea2-48b2-a7b5-b9783aeeb1d1",
   "metadata": {},
   "source": [
    "### Testing the model + submission\n",
    "\n",
    "Prepare the data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28832437-a021-405b-b5ac-7e6b33772f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the best saved trained model\n",
    "model=load_model(\"../models/contrastive_model.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b436d6d-be1c-4f95-9929-2030a28d8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load csv-data\n",
    "image_dir = \"../images/\"\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "train_data.image_id = train_data.image_id.apply(lambda x: x.strip()+\".JPG\")\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "test_data.image_id = test_data.image_id.apply(lambda x: x.strip()+\".JPG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752787a-f6f7-40d2-9ebb-d6aff943cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"turtle_id\"] = \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd511c-b490-4739-8724-b28c7778c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d461dd3-e5a1-4332-afe9-8b40ca9b4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(merged,\n",
    "                directory   = \"../images/\",\n",
    "                x_col       = \"image_id\" ,\n",
    "                y_col       = \"turtle_id\",\n",
    "                target_size = (224,224),\n",
    "                batch_size  = 2635,\n",
    "                class_mode  = 'sparse',\n",
    "                shuffle     = False)\n",
    "                #save_to_dir=\"output/\",  if you wanna save the cropped images\n",
    "                #save_prefix=\"\",\n",
    "                #save_format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016e733-6cec-44b8-a7a8-21b961a6868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af32e9-2d1e-4d99-a16b-fbc8f75214ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test pairs\n",
    "pairs_test, labels_test = make_pairs(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df3b46-ad57-4400-924b-92dddc9fdb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = pairs_test[:, 0]\n",
    "x_test_2 = pairs_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5e106-8a18-44e5-8b46-c86c50085980",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=model.predict([x_test_1, x_test_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2c59a-273c-4e00-bf44-5f450d6a3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f75d30-927f-4059-9613-c2fa17ec047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(pairs_test, labels_test, to_show=10, predictions=results, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a31156-80c0-4649-8c92-249a64c8df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_index = []\n",
    "predictions_probabilities = []\n",
    "result = []\n",
    "\n",
    "for i in range(0,len(pairs_test)):    \n",
    "    probabilities_sorted = []\n",
    "    index_sorted = [] \n",
    "    result = results[i]\n",
    "    y_preds_indices = np.argsort(result)[-5:]\n",
    "    top_5_values = [result[j] for j in y_preds_indices]\n",
    "    \n",
    "    #print(y_preds_indices)\n",
    "    #print(top_5_values)\n",
    "    for index in range(1,6):\n",
    "        probabilities_sorted.append(top_5_values[-index])\n",
    "        index_sorted.append(y_preds_indices[-index])\n",
    "        #print(probabilities_sorted)\n",
    "        #print(index_sorted)\n",
    "    predictions_probabilities.append(probabilities_sorted)\n",
    "    predictions_index.append(index_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436704c9-9be9-410f-b92c-1cb27aa70ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create labels to connect indices with turtle_ids (folder structure in train)\n",
    "labels = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a5b93-8934-4f0f-bc50-40c621b790b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe for image_ids in order of validation generator (folder structure in val)\n",
    "images_ids = list(val_sony_datagen.class_indices.keys())\n",
    "titles = ['image_id']\n",
    "test_data = pd.DataFrame(images_ids,columns=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a9dea-9c82-48ca-9fea-7231e2922939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv('../data/train_corrected.csv')\n",
    "#unique_turtle_ids = list(train_data['turtle_id'].unique())\n",
    "\n",
    "list = []\n",
    "array = []\n",
    "for line in predictions_index:\n",
    "    for id in line:\n",
    "        list.append(labels[id])\n",
    "    array.append(list)\n",
    "    list = []\n",
    "    \n",
    "titles = ['prediction1', 'prediction2','prediction3','prediction4','prediction5']\n",
    "submission = pd.DataFrame(array, columns= titles)\n",
    "\n",
    "#Insert image_ids from test_data\n",
    "\n",
    "submission.insert(loc=0, column='image_id', value=test_data['image_id'])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed2c07-4a05-40d6-984e-47483ddee993",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee12e2c-15ea-44b0-8fb8-c5d61693a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save submission data as CSV\n",
    "submission.to_csv('../data/submission_contrastive.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
