{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed52df3-21d0-45f1-bd56-f6e67402ce8f",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "* Read the picture files\n",
    "* Decode JPEG content to RGB pixels\n",
    "* Convert this into floating tensors\n",
    "* Rescale pixel values (between 0 to 255) to [0,1] interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30d8b791-974f-4d0a-8caa-ede55a07a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f37e70-1d19-488a-b83a-765a69d78864",
   "metadata": {},
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f4894d-e433-4c19-a02d-9a2d829791d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[HEIGHT, WIDTH, 3], name='image'))\n",
    "    model.add(tf.keras.layers.Flatten(data_format=\"channels_last\"))\n",
    "    # We want to have a simple linear model so we have \n",
    "    # no activation function. \n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6b7bf-3dac-424f-b21c-cd1ca7141b47",
   "metadata": {},
   "source": [
    "# Keras Preprocessing + Augmentation using ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "- Rescale is a value by which we will multiply the data before any other processing. Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our models to process (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e89af56-5a3d-4a8b-a83d-1c062a121874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.ImageDataGenerator at 0x29e40cd60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing using ImageDataGenerator - this is just a showcase what we can do with imagedatagenerator\n",
    "\n",
    "tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False, samplewise_center=False,\n",
    "    featurewise_std_normalization=False, samplewise_std_normalization=False,\n",
    "    zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0,\n",
    "    height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0,\n",
    "    channel_shift_range=0.0, fill_mode='nearest', cval=0.0,\n",
    "    horizontal_flip=False, vertical_flip=False, rescale=None,\n",
    "    preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f1fc5-2936-445f-a3a4-e1b56dd791dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we could maybe use this as follows: \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# flow_from_directory : Takes the path to a directory & generates batches of augmented data.\n",
    "# use \"rescale\" to scale array of original image pixel values to be between [0,1] and specify the parameter rescale=1./255.\n",
    "\n",
    "def read_and_preprocess(test_datagen, train_datagen, augment_randomly=False):\n",
    "    if augment_randomly=False\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "    return train_datagen, test_datagen\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "\n",
    "def generate_augmented_image(train_datagen, test_datagen, augment_randomly=False): \n",
    "     if augment_randomly=False\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                'data/train',\n",
    "                target_size=(150, 150),\n",
    "                batch_size=32,\n",
    "                class_mode='binary')\n",
    "\n",
    "        validation_generator = test_datagen.flow_from_directory(\n",
    "                'data/validation',\n",
    "                target_size=(150, 150),\n",
    "                batch_size=32,\n",
    "                class_mode='binary')\n",
    "        \n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "                'data/validation',\n",
    "                target_size=(150, 150),\n",
    "                batch_size=32,\n",
    "                class_mode='binary')\n",
    "        else:\n",
    "            \n",
    "\n",
    "    return generate_augmented_image(train_generator,  validation_generator,test_generator)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96ef46-38ee-4d4f-b0c5-5b8876cfb193",
   "metadata": {},
   "source": [
    "# Simple Model (Training) -- needs Update--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae4187f-2e33-4d6a-b7a5-357ae12caf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, batch_size):\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        # The model outputs one-hot-encoded logits, so we need\n",
    "        # use the sparse version of the crossentropy loss.\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    dataset = image_modeling.load_dataset(TRAIN_PATH, batch_size)                                 #update this \n",
    "    eval_dataset = image_modeling.load_dataset(EVAL_PATH, batch_size, training=False)             #update this\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model.fit(\n",
    "        train_generator, \n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=TRAINING_STEPS, \n",
    "        epochs=10,\n",
    "        callbacks=[tensorboard_callback],\n",
    "        model.save_weights('first_try.h5')  # always save your weights after training or during training\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf85740-6b77-452f-84a0-94392be035ac",
   "metadata": {},
   "source": [
    "Let us use Tensorboard to monitor our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fb911-bd4b-4b81-963c-ea3fa1919e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc16917-1bf2-4298-b0f7-5a063cc4871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a testing function.\n",
    "def test(model):\n",
    "    \n",
    "    test_dataset = image_modeling.load_dataset(TEST_PATH, batch_size=1, training=False)\n",
    "    model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39c2a2-43c9-492e-816e-c61512ef3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the testing function for our model\n",
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
