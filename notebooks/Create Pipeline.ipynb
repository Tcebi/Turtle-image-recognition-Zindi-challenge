{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc5ef11-45f6-4ecf-a184-7b438e336154",
   "metadata": {},
   "source": [
    "# Image Modelling - Pipeline Creation (Python file)\n",
    "In this notebook we will cover: \n",
    "- how to prepare images for training a neural network and using shell commands instead of pandas to do so\n",
    "- Weâ€™ll start by preparing the data in a way that it can be loaded into tensorflow, followed by the loading itself and checking if everything went fine. \n",
    "- Each step will be defined as a function, which we will directly write into a python file. \n",
    "\n",
    "In the second notebook we will import and use those functions in order to train a neural network that classifies our pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47483726-487f-4192-9619-19393cf4344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any file that gets constructed by the notebook.\n",
    "## noch anpassen \n",
    "!rm -f image_modeling.py ../data/train_noheader_split.csv ../data/test_noheader_split.csv ../data/train_noheader.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa45e36-1be0-443b-a8d8-63badf3ce8a7",
   "metadata": {},
   "source": [
    "The following cell defines a register cell magic which lets you write the content of a cell into a python script automatically, while still executing the cell. Mode 'a' (can be set with the -a flag) appends to the file while mode 'w' overwrites all existing lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c688f-64f6-4cfe-a750-a080f3f10a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some dark cell magic. Why not!\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def write_and_run(line, cell):\n",
    "    argz = line.split()\n",
    "    file = argz[-1]\n",
    "    mode = 'w'\n",
    "    if len(argz) == 2 and argz[0] == '-a':\n",
    "        mode = 'a'\n",
    "        print(\"Appended to file \", file)\n",
    "    else:\n",
    "        print('Written to file:', file)\n",
    "    with open(file, mode) as f:\n",
    "        f.write(cell.format(**globals()))        \n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6104569-ca79-4fd5-a5f9-ad2df66c84b8",
   "metadata": {},
   "source": [
    "Import needed libraries. `%%write_and_run image_modeling.py` is the call of the register cell magic from above in 'w' mode (default). It writes the imports at the beginning of the `image_modeling.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5228ad7-33bd-4840-8a7a-557150bb82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run image_modeling.py\n",
    "import pathlib\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83dd2d4-bed3-456a-874d-f89bad655b57",
   "metadata": {},
   "source": [
    "Print the tensorflow version and set the threshold for what messages will be logged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d8952-d5e8-47a3-8f20-ceb2ff358df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(v=tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62518635-52d3-4e86-8e80-979c756b1c72",
   "metadata": {},
   "source": [
    "Get the absolute path to the data folder, count all images and get the class names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321ec69-7efd-4193-b5ea-f3e595b75309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths as POSIX paths\n",
    "#home_path = str(pathlib.Path.home())\n",
    "data_dir = '../images'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "print(f'The total number of images is: {len(os.listdir(data_dir))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0c00a-73ba-4071-b4f4-60f40564a5a8",
   "metadata": {},
   "source": [
    "Let's have a look at some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b60cf-fd0d-4dfa-8886-78f088daeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all turtles images\n",
    "#turtles = list(data_dir.glob('*'))\n",
    "\n",
    "#for image in turtles[:2]:\n",
    "#    display.display(Image.open(str(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a411827-4128-4e48-8077-ff9b5073083d",
   "metadata": {},
   "source": [
    "## Data preparation using shell commands\n",
    "\n",
    "Now we will use shell commands to look at the data, clean the paths to the images and split our data into train and evaluation set.\n",
    "\n",
    "Let's look at the first five entries. \n",
    "First we use the [head](https://linuxhint.com/bash_head_tail_command/) command to generate the first five lines of the `train.csv`. Then we redirect the output of the [head](https://linuxhint.com/bash_head_tail_command/) command to the `/tmp/input.csv` via the ['>'](https://www.cs.ait.ac.th/~on/O/oreilly/unix/upt/ch13_01.htm#UPT-ART-1023) operator. We now print the content of this file with the [cat](https://www.interserver.net/tips/kb/linux-cat-command-usage-examples/?__cf_chl_f_tk=sbsfrwcq2e.iPk93oGmvT0LSXdGVW7BuzsZsRhl85GI-1642513145-0-gaNycGzNCOU) command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd750e6-05be-4835-9d36-c53c590d1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us take a look into the training set\n",
    "!head -5 ../data/train.csv > /tmp/input.csv \n",
    "!cat /tmp/input.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf9c784-c862-4415-9467-3ca84531c05a",
   "metadata": {},
   "source": [
    "### Change image_id to image_id_path \n",
    "To use the images later, we need the image_id within the csf file to be changed to the respective path of the image.\n",
    "As second step we create a csv file, where the header is excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62867b-9c13-4946-a3fb-ece7b0727733",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train.csv\",'r') as f:\n",
    "    with open(\"../data/train_noheader.csv\",'w') as f1:\n",
    "        next(f) # skip header line\n",
    "        for line in f:\n",
    "            f1.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c4a44-7f20-43a7-a40f-ed2d5b3d60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''home_path = str(pathlib.Path.home())\n",
    "df = pd.read_csv(\"../data/train.csv\",header=0)\n",
    "df[\"image_id\"] = df[\"image_id\"].apply(lambda x: home_path + '/neuefische/Capstone_Project_Turtle_Recall/images/' + x + \".JPG\")\n",
    "df.to_csv(\"../data/train_jpg.csv\",index=False)\n",
    "\n",
    "with open(\"../data/train_jpg.csv\",'r') as f:\n",
    "    with open(\"../data/train_jpg_noheader.csv\",'w') as f1:\n",
    "        next(f) # skip header line\n",
    "        for line in f:\n",
    "            f1.write(line)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194427a-4991-4257-953d-a201b6e545ef",
   "metadata": {},
   "source": [
    "Save a copy from train_jpg_noheader.csv to train_jpg_noheader_split.csv and conduct the split (remove 30 % images from train_split and save as test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619fed0-6979-4e96-af03-57129bd7075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the line-count for 30% of the data\n",
    "file = open(\"../data/train_noheader.csv\")\n",
    "reader = csv.reader(file)\n",
    "lines= round(len(list(reader))*0.3)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f1e08-cb83-4c2d-b6ff-2743e5f25ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat ../data/train_noheader.csv > ../data/train_noheader_split.csv \n",
    "sort -R ../data/train_noheader_split.csv --random-source=random.seed | split -l $(( $(wc -l <../data/train_noheader_split.csv) - 644)) - ../data/train_noheader_split\n",
    "\n",
    "mv ../data/train_noheader_splitaa ../data/train_noheader_split.csv\n",
    "mv ../data/train_noheader_splitab ../data/test_noheader_split.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9709d07-9411-42c1-8e35-52fb55f3944e",
   "metadata": {},
   "source": [
    "Check if new csv files have correct number of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8fa34-e106-41fc-ad16-71dae149f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wc -l ../data/train_noheader_split.csv\n",
    "wc -l ../data/test_noheader_split.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a43da-dc21-4647-bbd3-8c3c2a9b8521",
   "metadata": {},
   "source": [
    "### Next we want to extract the labels from the `train_split.csv`. \n",
    "\n",
    "- [awk](https://www.geeksforgeeks.org/awk-command-unixlinux-examples/) lets you, amongst other things, select fields separated by white spaces in a file.\n",
    "- [uniq](https://linuxhint.com/bash_uniq_command/) removes adjacent duplicate lines from a file.\n",
    "\n",
    "Why is the `sort` command used? --> We need all duplicates in adjacent files, to successfully remove them via 'uniq'\n",
    "Why are the ',' replaced with whitespaces? --> The 'awk' command selects field only separated by white spaces.\n",
    "\n",
    "Furthermore we check the number of labels in train_split and test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd579a-efc4-41fc-a838-1b4a727369ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels from the train data \n",
    "!cat ../data/train_noheader_split.csv | sed 's/,/ /g' | awk '{print $3}' | sort | uniq > /tmp/labels.txt\n",
    "#!cat /tmp/labels.txt\n",
    "!wc -l /tmp/labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1067e92-8b65-4cfd-af48-4c449350e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels from the test data \n",
    "!cat ../data/test_noheader_split.csv | sed 's/,/ /g' | awk '{print $3}' | sort | uniq > /tmp/labels.txt\n",
    "#!cat /tmp/labels.txt\n",
    "!wc -l /tmp/labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c61744-fda2-4392-9ff9-38aba8ef9e76",
   "metadata": {},
   "source": [
    "Great! With our random seed = 42 we have all unique turtle ID's in both train and test files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403717f-cda3-42c1-8ec1-934c6efa9b2f",
   "metadata": {},
   "source": [
    "## Define functions to process the data\n",
    "\n",
    "From now on we will use python and Tensorflow to define some variables and functions to be used in the second notebook when we train our CNN to classify images of turtles.\n",
    "\n",
    "We set some parameters for the model and call the register cell magic `write_and_run` again this time with the `-a` flag. This makes sure that the content of the cell is appended to `image_modeling.py` and existing lines are not overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ad3ab-0874-4919-b8bd-369b6b897c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "#Get unique_turtle_ids from train.csv (without header)\n",
    "file = open(\"../data/train_noheader.csv\")\n",
    "reader = csv.reader(file)\n",
    "turtle_ids = []\n",
    "for i in list(reader):\n",
    "    turtle_ids.append(i[2])\n",
    "unique_turtle_ids = list(dict.fromkeys(turtle_ids))\n",
    "\n",
    "# We set some parameters for the model\n",
    "HEIGHT = 224 #image height\n",
    "WIDTH = 224 #image width\n",
    "CHANNELS = 3 #image RGB channels\n",
    "CLASS_NAMES = unique_turtle_ids\n",
    "NCLASSES = len(CLASS_NAMES)\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "VALIDATION_SIZE = 370\n",
    "VALIDATION_STEPS = VALIDATION_SIZE // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a4fc2-e597-46a3-beed-cbbbfc6e4cfe",
   "metadata": {},
   "source": [
    "### Save image as float32 for Tensorflow\n",
    "We define a function which takes the jpeg image and returns the image in a format which can be used by Tensorflow. We also write it to the end of `image_modeling.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1242198-e5b3-4724-bbb1-28bafe35be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# Define the function that decodes in the images\n",
    "def decode_image(image, reshape_dim):\n",
    "    # JPEG is a compressed image format. So we want to \n",
    "    # convert this format to a numpy array we can compute with.\n",
    "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
    "    # 'decode_jpeg' returns a tensor of type uint8. We need for \n",
    "    # the model 32bit floats. Actually we want them to be in \n",
    "    # the [0,1] interval.\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Now we can resize to the desired size.\n",
    "    image = tf.image.resize(image, reshape_dim)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff9407-ab22-4c1f-aaad-e0f7c4ac218a",
   "metadata": {},
   "source": [
    "Let us look at the result of the `decode_image` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f3031-cae9-4493-9124-83d6e991f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us test our decoding function.\n",
    "img = tf.io.read_file('../images/ID_0014D1K8.JPG')    \n",
    "\n",
    "# TODO: take the function above and decode the image\n",
    "img = decode_image(img, [224,224])\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a3ce7-35a5-415c-b0fd-8fe115ae8044",
   "metadata": {},
   "source": [
    "We need a function that takes a row containing paths and classes and returns the actual images and a label vector which is true at the position of the class of the image, defined by CLASS_NAMES above and false otherwise (one-hot-encoding). The decode_dataset function does this for us. It will be used later and written to the end of `image_modeling.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf14785-15f5-42de-b4ac-8ab10844ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Capstone_directory = os.getcwd().strip(\"/notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf09054-424b-4557-bb85-f1ef875ee47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# The train set actually gives only the paths to the training images.\n",
    "# We want to create a dataset of training images, so we need a \n",
    "# function that can handle this for us.\n",
    "def decode_dataset(data_row):\n",
    "    record_defaults = ['path', 'image_location', 'turtle_id']\n",
    "    filename, image_location_string, turtle_id_string = tf.io.decode_csv(data_row, record_defaults)\n",
    "    image_bytes = tf.io.read_file(filename=\"/\"+Capstone_directory+\"/\"+\"images/\"+filename+\".JPG\")\n",
    "    turtle_id = tf.math.equal(turtle_id_string, CLASS_NAMES)\n",
    "    return image_bytes, turtle_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c7f5d-dd7b-4c5f-954d-37def552faad",
   "metadata": {},
   "source": [
    "In the next cell you can see how a Tensorflow data set will look like. Tensorflow data sets will be iterable objects and we can use `.decode_csv` to unpack the content into a path and a class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9f499-6b73-4685-bbe9-874a04b97ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset('../data/train.csv')\n",
    "it = iter(dataset)\n",
    "record_defaults = ['path', 'image_location', 'turtle_id'] # defines dtype\n",
    "# output dtype of decode_csv will be two strings. could have written ['chicken','egg'] with same outcome. But not e.g. [1,'class'].\n",
    "filename, image_location_string, turtle_id_string = tf.io.decode_csv(next(it), record_defaults)\n",
    "filename, image_location_string, turtle_id_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62fad04-0eb6-42c8-b165-9eddb24fe3ba",
   "metadata": {},
   "source": [
    "### Augmentation (to improve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9540af-30f5-4b09-a96d-1e3091d2cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# Next we construct a function for pre-processing the images.\n",
    "def read_and_preprocess(image_bytes, label, augment_randomly=False):\n",
    "    if augment_randomly: \n",
    "        image = decode_image(image_bytes, [HEIGHT + 8, WIDTH + 8])\n",
    "        # TODO: Augment the image.\n",
    "        import random\n",
    "        offset_h = random.randint(0,8)\n",
    "        offset_w = random.randint(0,8)\n",
    "        image = image[offset_h:224+offset_h,offset_w:224+offset_w]\n",
    "    else:\n",
    "        image = decode_image(image_bytes, [HEIGHT, WIDTH])\n",
    "    return image, label\n",
    "\n",
    "def read_and_preprocess_with_augmentation(image_bytes, label): \n",
    "    return read_and_preprocess(image_bytes, label, augment_randomly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a084818-76c8-4e1a-af95-59c40083a8ae",
   "metadata": {},
   "source": [
    "Finally we can define a function that loads and preprocesses our data by combining the functions defined above. \n",
    "- the `load_dataset` function applies (`map`) the `decode_dataset` to every element in the dataset.\n",
    "- for training:\n",
    "    - the data should use your augmentation implementation (`#TODO`).\n",
    "    - then the data will be [shuffled](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle) to avoid the risk to create batches that are not representative of the overall dataset. Second answer in [this](https://datascience.stackexchange.com/questions/24511/why-should-the-data-be-shuffled-for-machine-learning-tasks) thread for more details.\n",
    "    - we can go through the dataset infinite times.\n",
    "- for evaluation:\n",
    "    - the data is neither shuffled or augmented, just read and preprocessed.\n",
    "    - we only need to go through the whole dataset once, hence `repeat(count=1)`. Will just stop after end is reached.\n",
    "- finally batches of size `batch_size` will be produced with each iteration step.\n",
    "- with `prefetch(buffer_size=AUTOTUNE)` an optimized number batches are prepared while prior ones are trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39892e15-94f7-4637-ab45-3030395df6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# Now we can create the dataset.\n",
    "def load_dataset(file_of_filenames, batch_size, training=True):\n",
    "    # We create a TensorFlow Dataset from the list of files.\n",
    "    # This dataset does not load the data into memory, but instead\n",
    "    # pulls batches one after another.\n",
    "    dataset = tf.data.TextLineDataset(filenames=file_of_filenames).\\\n",
    "        map(decode_dataset)\n",
    "    \n",
    "    if training: #Use augmentation\n",
    "        dataset = dataset.map(read_and_preprocess_with_augmentation).\\\n",
    "            shuffle(SHUFFLE_BUFFER).\\\n",
    "            repeat(count=None) # Infinite iterations\n",
    "    else: \n",
    "        # Evaluation or testing\n",
    "        dataset = dataset.map(read_and_preprocess).\\\n",
    "            repeat(count=1) # One iteration\n",
    "            \n",
    "    # The dataset will produce batches of BATCH_SIZE and will\n",
    "    # automatically prepare an optimized number of batches while the prior one is\n",
    "    # trained on.\n",
    "    return dataset.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128dc2e5-a3ca-406d-8e9e-3a5aec15271d",
   "metadata": {},
   "source": [
    "#### Let us see how the `load_dataset` function works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d948e-7a9a-4fe2-b9f2-bce517191fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see, if data loading works as intended.\n",
    "train_path = '../data/train_noheader.csv'\n",
    "train_data = load_dataset(train_path, 1)\n",
    "# Create an iterator that runs over the training dataset.\n",
    "it = iter(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04b621-4864-4816-a91a-1a7c5d8f0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and see the pictures and labels\n",
    "img_batch, labels = next(it)\n",
    "image = img_batch[0]\n",
    "plt.imshow(image)\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a29ad0-cf53-46ac-aee8-cc435423af29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
