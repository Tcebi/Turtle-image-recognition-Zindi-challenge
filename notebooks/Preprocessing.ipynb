{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed52df3-21d0-45f1-bd56-f6e67402ce8f",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "* Read the picture files\n",
    "* Decode JPEG content to RGB pixels\n",
    "* Convert this into floating tensors\n",
    "* Rescale pixel values (between 0 to 255) to [0,1] interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d8b791-974f-4d0a-8caa-ede55a07a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec4043-f9c7-4c31-94fa-5712fcd3c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the images into Train, Test folders\n",
    "import shutil, os\n",
    "\n",
    "#read labels from the csv\n",
    "df = pd.read_csv('../data/train.csv', sep=\";\", names=['image_id','image_location','turtle_id'])\n",
    "\n",
    "#Extract the labels and store in a new data frame called labels\n",
    "labels = df.sort_values('turtle_id')\n",
    "\n",
    "#Create a Python list of Unique labels in data frame labels\n",
    "class_names = list(labels.Class.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9f175-e15a-47e5-8d1a-3f2606a256a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the directories\n",
    "train_dir=\"../images_test/train\"\n",
    "val_dir = \"../images_test/validation\"\n",
    "test_dir=\"../images_test/test\"\n",
    "train=pd.read_csv('../data/train.csv')\n",
    "\n",
    "df_test=pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f37e70-1d19-488a-b83a-765a69d78864",
   "metadata": {},
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4894d-e433-4c19-a02d-9a2d829791d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    return model\n",
    "model = linear_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d726f-0ab1-4c78-b9b4-101d505348bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6b7bf-3dac-424f-b21c-cd1ca7141b47",
   "metadata": {},
   "source": [
    "# Keras Preprocessing + Augmentation using ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "- Rescale is a value by which we will multiply the data before any other processing. Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our models to process (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89af56-5a3d-4a8b-a83d-1c062a121874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing using ImageDataGenerator - this is just a showcase what we can do with imagedatagenerator\n",
    "\n",
    "tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False, samplewise_center=False,\n",
    "    featurewise_std_normalization=False, samplewise_std_normalization=False,\n",
    "    zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0,\n",
    "    height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0,\n",
    "    channel_shift_range=0.0, fill_mode='nearest', cval=0.0,\n",
    "    horizontal_flip=False, vertical_flip=False, rescale=None,\n",
    "    preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f1fc5-2936-445f-a3a4-e1b56dd791dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we could maybe use this as follows: \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# flow_from_directory : Takes the path to a directory & generates batches of augmented data.\n",
    "# use \"rescale\" to scale array of original image pixel values to be between [0,1] and specify the parameter rescale=1./255.\n",
    "\n",
    "def preprocess(augment_randomly=False):\n",
    "    if augment_randomly==False:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "    return train_datagen, test_datagen\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "\n",
    "def generate_augmented_image(train_datagen, test_datagen, augment_randomly=False): \n",
    "    if augment_randomly == False:\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                '../images_test/train',\n",
    "                target_size=(150, 150),\n",
    "                batch_size=2,\n",
    "                class_mode='input')\n",
    "\n",
    "        validation_generator = test_datagen.flow_from_directory(\n",
    "                '../images_test/validation',\n",
    "                target_size=(150, 150),\n",
    "                batch_size=2,\n",
    "                class_mode='input')\n",
    "        \n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "                '../images_test/test',\n",
    "                target_size=(150, 150),\n",
    "                batch_size=2,\n",
    "                class_mode='input')\n",
    "    \n",
    "            \n",
    "\n",
    "    return train_generator, validation_generator,test_generator\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96ef46-38ee-4d4f-b0c5-5b8876cfb193",
   "metadata": {},
   "source": [
    "# Simple Model (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4187f-2e33-4d6a-b7a5-357ae12caf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model,batch_size=2):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        # The model outputs one-hot-encoded logits, so we need\n",
    "        # use the sparse version of the crossentropy loss.\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    train_datagen, test_datagen = preprocess()\n",
    "    train_generator, validation_generator,test_generator = generate_augmented_image(train_datagen, test_datagen, augment_randomly=False)\n",
    "    \n",
    "    model.fit(\n",
    "        train_generator, \n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=100 // batch_size, \n",
    "        epochs=10)\n",
    "        #callbacks=[tensorboard_callback])\n",
    "    \n",
    "    model.save_weights('simple_model.h5')  # always save your weights after training or during training\n",
    "    \n",
    "     \n",
    "    \n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb989c-2c82-437a-bbc9-14eac07d9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train our model using the prior defined functions \n",
    "model = linear_model()\n",
    "\n",
    "trained_model = train_and_evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf85740-6b77-452f-84a0-94392be035ac",
   "metadata": {},
   "source": [
    "Let us use Tensorboard to monitor our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fb911-bd4b-4b81-963c-ea3fa1919e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc16917-1bf2-4298-b0f7-5a063cc4871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a testing function.\n",
    "def test(model):\n",
    "    \n",
    "    model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39c2a2-43c9-492e-816e-c61512ef3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the testing function for our model\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b61c9-8f61-43ab-979a-258806819377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
